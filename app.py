import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier

# å¯¼å…¥ PRO/META æ¨¡å‹æ¥å£
from models.pro_model import predict_model_pro
from models.model_pro_ensemble import predict_model_pro_ensemble
from models.predict_model_meta import predict_model_meta
from similarity_matcher import SimilarityMatcher

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ CSS Styling â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<style>
.stApp { background: linear-gradient(135deg, #f0f8ff, #e6e6fa); }
.company-name { font-size:1.1em; font-weight:600;
  text-shadow:1px 1px 2px rgba(0,0,0,0.2); }
.stTextInput>div>div>input { max-width:200px; }
.stButton>button { margin-top:4px; margin-bottom:8px; }
</style>
""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ åŠ è½½æ¨¡å‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_models():
    base = Path(__file__).parent / "data"
    df = pd.read_excel(base / "new_matches.xlsx")
    feat_cols = [c for c in df.columns if c not in ["æ¯”èµ›","æ¯”èµ›ç»“æœ"]]
    X = df[feat_cols].values

    # éšå«æ¦‚ç‡è½¬æ¢
    X_imp = X.copy()
    for j in range(0, X_imp.shape[1], 3):
        inv = 1 / X_imp[:, j:j+3]
        X_imp[:, j:j+3] = inv / inv.sum(axis=1, keepdims=True)

    # æ ‡ç­¾
    y = df["æ¯”èµ›ç»“æœ"].map({"ä¸»èƒœ":0,"å¹³å±€":1,"å®¢èƒœ":2}).values

    # â€” é˜¶æ®µ1ï¼šå¹³å±€ vs éå¹³å±€ â€” #
    y_draw = (y == 1).astype(int)
    draw_clf = HistGradientBoostingClassifier(
        learning_rate=0.01, max_depth=5, loss="log_loss", random_state=42
    ).fit(X_imp, y_draw)
    tree_clf = DecisionTreeClassifier(max_depth=3, random_state=42).fit(X_imp, y_draw)

    # â€” é˜¶æ®µ2ï¼šèƒœè´Ÿæ¨¡å‹ â€” #
    mask = (y != 1)
    X_wl, y_wl = X_imp[mask], (y[mask] == 0).astype(int)
    winlose_clf = HistGradientBoostingClassifier(
        learning_rate=0.01, max_depth=5, loss="log_loss", random_state=42
    ).fit(X_wl, y_wl)

    # â€” å¤‡ç”¨ä¸‰åˆ†ç±»æ¨¡å‹ï¼Œç”¨ sample_weight æ¨¡æ‹Ÿ class_weight â€” #
    class_weights = {0:1.0, 1:0.8, 2:1.0}
    w = np.array([ class_weights[yi] for yi in y ])
    multi_clf = HistGradientBoostingClassifier(
        learning_rate=0.01, max_depth=5, loss="log_loss", random_state=42
    ).fit(X_imp, y, sample_weight=w)

    return feat_cols, draw_clf, tree_clf, winlose_clf, multi_clf

soccer_feats, draw_clf, tree_clf, winlose_clf, multi_clf = load_models()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ é¡µé¢è®¾ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ç»¼åˆå†·é—¨ Boost è¶³çƒé¢„æµ‹", layout="wide")
st.title("âš½ è¶³çƒæ¯”èµ›é¢„æµ‹ç³»ç»Ÿ")

company_order = ["Bet365","ç«‹åš","Interwetten","Pinnacle","William Hill"]
outcomes      = ["ä¸»èƒœ","å¹³å±€","å®¢èƒœ"]
feature_cols  = [f"{c}_{o}" for c in company_order for o in outcomes]

# åˆå§‹åŒ– session_state
if "input_df" not in st.session_state:
    st.session_state.input_df = pd.DataFrame(columns=feature_cols)
if "matcher" not in st.session_state:
    hist_path = Path(__file__).parent / "data" / "prediction_results (43).xlsx"
    st.session_state.matcher = SimilarityMatcher(str(hist_path))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ•°æ®è¾“å…¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€
mode = st.radio("ğŸ“¥ æ•°æ®è¾“å…¥æ–¹å¼", ["ä¸Šä¼ æ–‡ä»¶","æ‰‹åŠ¨å½•å…¥"], horizontal=True)
if mode == "ä¸Šä¼ æ–‡ä»¶":
    up = st.file_uploader("ä¸Šä¼ èµ”ç‡æ–‡ä»¶ (Excel/CSVï¼Œæ¯è¡Œ15åˆ—)", type=["xlsx","csv"])
    if up:
        df_up = pd.read_csv(up) if up.name.endswith(".csv") else pd.read_excel(up)
        st.session_state.input_df = df_up[feature_cols]
        st.success(f"âœ… å·²è¯»å– {len(df_up)} åœºæ¯”èµ›")
        st.dataframe(st.session_state.input_df)
else:
    st.subheader("ğŸ–Š æ‰‹åŠ¨å½•å…¥ (é€å…¬å¸ä¸€è¡Œ)")
    with st.form("manual", clear_on_submit=True):
        vals_in = {}
        for comp in company_order:
            c1,c2 = st.columns([1,2])
            c1.markdown(f"<div class='company-name'>{comp}</div>", unsafe_allow_html=True)
            vals_in[comp] = c2.text_input("", placeholder="2.05 3.60 3.50", key=f"man_{comp}")
        if st.form_submit_button("æ·»åŠ æ¯”èµ›"):
            row, ok = [], True
            for comp in company_order:
                parts = vals_in[comp].split()
                if len(parts)!=3:
                    st.error(f"âš ï¸ {comp} éœ€è¾“å…¥ 3 ä¸ªèµ”ç‡"); ok=False; break
                row += [float(x) for x in parts]
            if ok:
                new_df = pd.DataFrame([row], columns=feature_cols)
                st.session_state.input_df = pd.concat(
                    [st.session_state.input_df, new_df], ignore_index=True
                )
                st.success("âœ… æ·»åŠ æˆåŠŸï¼Œè¾“å…¥æ¡†å·²æ¸…ç©º")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ å†å²ç›¸ä¼¼æ¨è â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not st.session_state.input_df.empty:
    st.subheader("ğŸ” å†å²ç›¸ä¼¼æ¯”èµ›æ¨è")
    df_pro    = predict_model_pro(st.session_state.input_df)
    prob_cols = [c for c in df_pro.columns if c.startswith("P(")]
    for pc in prob_cols: df_pro[pc].fillna(0, inplace=True)
    ens_in = pd.concat([
        st.session_state.input_df.reset_index(drop=True),
        df_pro[["average_gap"] + prob_cols].reset_index(drop=True)
    ], axis=1)
    try:
        df_ens = predict_model_pro_ensemble(ens_in)
    except:
        df_ens = pd.DataFrame({
            "PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ": ["å¹³å±€"]*len(df_pro),
            "PROèåˆæ¨¡å‹_gap": [0.0]*len(df_pro)
        })
    try:
        df_meta = predict_model_meta(st.session_state.input_df)
    except:
        df_meta = pd.DataFrame()
    for i in range(len(st.session_state.input_df)):
        q = {
            "PRO_gap": df_pro.loc[i,"average_gap"],
            "PROèåˆæ¨¡å‹_gap": df_ens.loc[i,"PROèåˆæ¨¡å‹_gap"],
            "èåˆä¿¡å¿ƒ": df_meta.loc[i,"èåˆä¿¡å¿ƒ"] if "èåˆä¿¡å¿ƒ" in df_meta else 0,
            "æ¨èæ€»åˆ†": df_meta.loc[i,"æ¨èæ€»åˆ†"] if "æ¨èæ€»åˆ†" in df_meta else 0,
            "pair": f"{df_pro.loc[i,'æœ€ç»ˆé¢„æµ‹ç»“æœ']}-{df_ens.loc[i,'PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ']}"
        }
        try:
            sims = st.session_state.matcher.query(q, k=5)
        except:
            sims = pd.DataFrame()
        st.markdown(f"**ç¬¬ {i+1} åœº** å†å²ç›¸ä¼¼æ¯”èµ›ï¼š")
        st.dataframe(sims.reset_index(drop=True))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ é¢„æµ‹é€»è¾‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not st.session_state.input_df.empty and st.button("ğŸ¯ è¿è¡Œé¢„æµ‹"):
    df_in     = st.session_state.input_df.copy().fillna(method="ffill")
    M         = len(df_in)
    odds      = df_in[soccer_feats].values.astype(float)
    X_imp_new = odds.copy()
    for j in range(0, X_imp_new.shape[1], 3):
        inv = 1 / X_imp_new[:, j:j+3]
        X_imp_new[:, j:j+3] = inv / inv.sum(axis=1, keepdims=True)

    # 1ï¸âƒ£ Draw é˜¶æ®µèåˆ + Boost
    p_hgb       = draw_clf.predict_proba(X_imp_new)[:,1]
    p_tree      = tree_clf.predict_proba(X_imp_new)[:,1]
    p_base_draw = 0.6*p_hgb + 0.4*p_tree
    alpha,gamma = 0.10,0.50
    p_draw      = p_base_draw + alpha * np.power(1-p_base_draw, gamma)
    p_draw      = np.clip(p_draw, 0, 1)

    # 2ï¸âƒ£ èƒœè´Ÿé˜¶æ®µ
    p_wl   = winlose_clf.predict_proba(X_imp_new)
    p_base = np.zeros((M,3))
    p_base[:,1] = p_draw
    p_base[:,0] = p_wl[:,1]*(1-p_draw)
    p_base[:,2] = p_wl[:,0]*(1-p_draw)

    # 3ï¸âƒ£ PRO+ensemble
    df_pro2 = predict_model_pro(df_in)
    prob2   = [c for c in df_pro2.columns if c.startswith("P(")]
    for pc in prob2: df_pro2[pc].fillna(0, inplace=True)
    ens2_in = pd.concat([
        df_in.reset_index(drop=True),
        df_pro2[["average_gap"]+prob2].reset_index(drop=True)
    ], axis=1)
    try:
        df_ens2 = predict_model_pro_ensemble(ens2_in)
        p_ens   = df_ens2[[f"P({o})" for o in outcomes]].values
    except:
        p_ens = np.zeros_like(p_base)

    # 4ï¸âƒ£ META
    try:
        df_meta2= predict_model_meta(df_in)
        p_meta  = df_meta2[[f"P({o})" for o in outcomes]].values
    except:
        p_meta = np.zeros_like(p_base)

    # 5ï¸âƒ£ Multi åˆ†ç±»æ¨¡å‹
    p_multi = multi_clf.predict_proba(X_imp_new)

    # 6ï¸âƒ£ å››è·¯èåˆ + å½’ä¸€åŒ–
    # â€”â€” 6) äº”è·¯èåˆ â€”â€”  â¬…ï¸ ç”¨â€œå››æƒé‡â€æ›¿æ¢å‡å€¼
    w_base, w_ens, w_meta, w_multi = 0.10, 0.70, 0.10, 0.00
    wsum   = w_base + w_ens + w_meta + w_multi          # =1.0

    p_final = (w_base  * p_base  +
           w_ens   * p_ens   +
           w_meta  * p_meta  +
           w_multi * p_multi) / wsum

    p_final /= p_final.sum(axis=1, keepdims=True)        # å½’ä¸€åŒ–

    # 7ï¸âƒ£ è¾“å‡º
    preds = [outcomes[k] for k in p_final.argmax(axis=1)]
    df_res = pd.DataFrame(p_final*100, columns=[f"{o}(%)" for o in outcomes])
    df_res.insert(0,"æœ€ç»ˆé¢„æµ‹",preds)
    df_res.index = np.arange(1,M+1); df_res.index.name="æ¯”èµ›ç¼–å·"

    st.subheader("ğŸ“Š ç»¼åˆæ¨¡å‹é¢„æµ‹ç»“æœ")
    st.dataframe(df_res, use_container_width=True)
    csv = df_res.to_csv(index=True).encode("utf-8-sig")
    st.download_button("â¬‡ï¸ ä¸‹è½½ç»“æœ", csv, "predictions.csv", "text/csv")
