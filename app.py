import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.ensemble import HistGradientBoostingClassifier

# å¯¼å…¥ PRO å’Œ META æ¨¡å‹æ¥å£
from models.pro_model import predict_model_pro
from models.model_pro_ensemble import predict_model_pro_ensemble
from models.predict_model_meta import predict_model_meta
from similarity_matcher import SimilarityMatcher

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ CSS Styling â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<style>
.stApp { background: linear-gradient(135deg, #f0f8ff, #e6e6fa); }
.company-name { font-size:1.1em; font-weight:600; text-shadow:1px 1px 2px rgba(0,0,0,0.2); }
.stTextInput>div>div>input { max-width:200px; }
.stButton>button { margin-top:4px; margin-bottom:8px; }
</style>
""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ åŠ è½½ äºŒé˜¶æ®µä¸å¤šåˆ†ç±»æ¨¡å‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_models():
    data_file = Path(__file__).parent / 'data' / 'new_matches.xlsx'
    df = pd.read_excel(data_file)
    feat_cols = [c for c in df.columns if c not in ['æ¯”èµ›','æ¯”èµ›ç»“æœ']]
    X = df[feat_cols].values
    # éšå«æ¦‚ç‡è½¬æ¢
    X_imp = X.copy()
    for j in range(0, X_imp.shape[1], 3):
        inv = 1 / X_imp[:, j:j+3]
        X_imp[:, j:j+3] = inv / inv.sum(axis=1, keepdims=True)
    y = df['æ¯”èµ›ç»“æœ'].map({'ä¸»èƒœ':0,'å¹³å±€':1,'å®¢èƒœ':2}).values
    # æ ·æœ¬æƒé‡
    w = np.array([1.0 if yi==0 else 0.6 if yi==1 else 1.0 for yi in y])
    # ä¸€é˜¶æ®µï¼šå¹³å±€ vs éå¹³å±€
    y_draw = (y == 1).astype(int)
    draw_clf = HistGradientBoostingClassifier(
        learning_rate=0.01, max_depth=5, loss='log_loss', random_state=42
    )
    draw_clf.fit(X_imp, y_draw)
    # äºŒé˜¶æ®µï¼šä¸»èƒœ vs å®¢èƒœï¼ˆéå¹³å±€å­é›†ï¼‰
    mask = (y != 1)
    X_wl, y_wl = X_imp[mask], (y[mask] == 0).astype(int)
    winlose_clf = HistGradientBoostingClassifier(
        learning_rate=0.01, max_depth=5, loss='log_loss', random_state=42
    )
    winlose_clf.fit(X_wl, y_wl)
    # å¤šåˆ†ç±»å¤‡ä»½
    multi_clf = HistGradientBoostingClassifier(
        learning_rate=0.01, max_depth=5, loss='log_loss', random_state=42
    )
    multi_clf.fit(X_imp, y, sample_weight=w)
    return feat_cols, draw_clf, winlose_clf, multi_clf

soccer_feats, draw_clf, winlose_clf, multi_clf = load_models()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ é¡µé¢è®¾ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title='äºŒé˜¶æ®µç»¼åˆè¶³çƒé¢„æµ‹å™¨', layout='wide')
st.title('âš½ äºŒé˜¶æ®µç»¼åˆè¶³çƒæ¯”èµ›é¢„æµ‹å™¨')

company_order = ['Bet365','ç«‹åš','Interwetten','Pinnacle','William Hill']
outcomes      = ['ä¸»èƒœ','å¹³å±€','å®¢èƒœ']
feature_cols  = [f"{c}_{o}" for c in company_order for o in outcomes]
num_feat      = len(feature_cols)

# Session state åˆå§‹åŒ–
if 'input_df' not in st.session_state:
    st.session_state.input_df = pd.DataFrame(columns=feature_cols)
if 'matcher' not in st.session_state:
    st.session_state.matcher = SimilarityMatcher(
        str(Path(__file__).parent / 'data' / 'prediction_results (43).xlsx')
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ•°æ®è¾“å…¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€
mode = st.radio('æ•°æ®è¾“å…¥æ–¹å¼', ['ğŸ“ ä¸Šä¼ æ–‡ä»¶','ğŸ–Š æ‰‹åŠ¨å½•å…¥'], horizontal=True)
if mode == 'ğŸ“ ä¸Šä¼ æ–‡ä»¶':
    up = st.file_uploader('ä¸Šä¼ æ–‡ä»¶ (15 åˆ—èµ”ç‡)', type=['xlsx','csv'])
    if up:
        df_up = pd.read_csv(up) if up.name.endswith('.csv') else pd.read_excel(up)
        st.session_state.input_df = df_up[feature_cols]
        st.success(f'âœ… å·²è¯»å– {len(df_up)} åœºæ¯”èµ›')
        st.dataframe(st.session_state.input_df)
else:
    st.subheader('ğŸ–Š æ‰‹åŠ¨å½•å…¥')
    with st.form('manual', clear_on_submit=True):
        inputs = {}
        for comp in company_order:
            c1, c2 = st.columns([1,2])
            c1.markdown(f"<div class='company-name'>{comp}</div>", unsafe_allow_html=True)
            inputs[comp] = c2.text_input('', placeholder='2.05 3.60 3.50', key=f'man_{comp}')
        if st.form_submit_button('æ·»åŠ æ¯”èµ›'):
            vals=[]
            ok=True
            for comp in company_order:
                parts=inputs[comp].split()
                if len(parts)!=3:
                    st.error(f'{comp} éœ€è¾“å…¥3ä¸ªèµ”ç‡')
                    ok=False
                    break
                vals.extend([float(x) for x in parts])
            if ok:
                new = pd.DataFrame([vals], columns=feature_cols)
                st.session_state.input_df = pd.concat([st.session_state.input_df, new], ignore_index=True)
                st.success('âœ… æ·»åŠ æˆåŠŸ')

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ å†å²åŒ¹é… â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not st.session_state.input_df.empty:
    st.subheader('ğŸ” å†å²ç›¸ä¼¼æ¯”èµ›æ¨è')
    df_pro = predict_model_pro(st.session_state.input_df)
    prob_cols = [c for c in df_pro.columns if c.startswith('P(')]
    for pc in prob_cols:
        df_pro[pc].fillna(0, inplace=True)
    ens_in = pd.concat([
        st.session_state.input_df.reset_index(drop=True),
        df_pro[['average_gap']+prob_cols].reset_index(drop=True)
    ], axis=1)
    try:
        df_ens = predict_model_pro_ensemble(ens_in)
    except:
        df_ens = pd.DataFrame({'PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ':['å¹³å±€']*len(df_pro),'PROèåˆæ¨¡å‹_gap':[0]*len(df_pro)})
    try:
        df_meta = predict_model_meta(st.session_state.input_df)
    except:
        df_meta = pd.DataFrame()
    for i in range(len(st.session_state.input_df)):
        q={
            'PRO_gap':df_pro.loc[i,'average_gap'],
            'PROèåˆæ¨¡å‹_gap':df_ens.loc[i,'PROèåˆæ¨¡å‹_gap'],
            'èåˆä¿¡å¿ƒ':df_meta.loc[i,'èåˆä¿¡å¿ƒ'] if 'èåˆä¿¡å¿ƒ' in df_meta else 0,
            'æ¨èæ€»åˆ†':df_meta.loc[i,'æ¨èæ€»åˆ†'] if 'æ¨èæ€»åˆ†' in df_meta else 0,
            'pair':f"{df_pro.loc[i,'æœ€ç»ˆé¢„æµ‹ç»“æœ']}-{df_ens.loc[i,'PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ']}"
        }
        try:
            sims = st.session_state.matcher.query(q, k=3)
        except:
            sims = pd.DataFrame()
        st.markdown(f"ç¬¬{i+1}åœº:")
        st.dataframe(sims)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ äºŒé˜¶æ®µé¢„æµ‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not st.session_state.input_df.empty and st.button('ğŸ¯ è¿è¡Œé¢„æµ‹'):
    df_in = st.session_state.input_df.copy().fillna(method='ffill')
    M = len(df_in)
    odds = df_in[soccer_feats].values.astype(float)
    X_imp_new = odds.copy()
    for j in range(0, X_imp_new.shape[1], 3):
        inv=1/X_imp_new[:,j:j+3]
        X_imp_new[:,j:j+3]=inv/inv.sum(axis=1,keepdims=True)
    # 1) å¹³å±€æ¦‚ç‡
    p_draw = draw_clf.predict_proba(X_imp_new)[:,1]
    # 2) èƒœè´Ÿæ¦‚ç‡
    p_wl = winlose_clf.predict_proba(X_imp_new)
    # åˆæˆåŸºç¡€æ¦‚ç‡
    p_base = np.zeros((M,3))
    p_base[:,1] = p_draw
    p_base[:,0] = p_wl[:,1]*(1-p_draw)
    p_base[:,2] = p_wl[:,0]*(1-p_draw)
    # PRO ensemble
    df_pro2 = predict_model_pro(df_in)
    prob2 = [c for c in df_pro2.columns if c.startswith('P(')]
    for pc in prob2: df_pro2[pc].fillna(0,inplace=True)
    ens2_in = pd.concat([df_in.reset_index(drop=True), df_pro2[['average_gap']+prob2]], axis=1)
    try:
        df_ens2 = predict_model_pro_ensemble(ens2_in)
        p_ens = df_ens2[[f'P({o})' for o in outcomes]].values
    except:
        p_ens = np.zeros_like(p_base)
    # META
    try:
        df_m2 = predict_model_meta(df_in)
        p_meta = df_m2[[f'P({o})' for o in outcomes]].values
    except:
        p_meta = np.zeros_like(p_base)
    # èåˆ
    p_final = (p_base + p_ens + p_meta)/3
    p_final /= p_final.sum(axis=1,keepdims=True)
    preds = [outcomes[i] for i in np.argmax(p_final,axis=1)]
    df_res = pd.DataFrame(p_final*100, columns=[f'{o}(%)' for o in outcomes])
    df_res.insert(0,'é¢„æµ‹',preds)
    df_res.index = np.arange(1,M+1)
    df_res.index.name='æ¯”èµ›'
    st.subheader('é¢„æµ‹ç»“æœ')
    st.dataframe(df_res,use_container_width=True)
    st.download_button('â¬‡ ä¸‹è½½', df_res.to_csv(index=True).encode('utf-8-sig'),'preds.csv','text/csv')
