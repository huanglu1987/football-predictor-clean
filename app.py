# app.py  â€“  åŠ å…¥ CV / Range / Pdiff ç‰¹å¾ç‰ˆ + gap å·®å€¼æ¨¡å¼å±•ç¤ºï¼ˆä¸¤åˆ—å¯¹é½è¡¨æ ¼ + å¯¼å‡º + å¼ºå‚è€ƒæ ‡è®°ï¼‰
import streamlit as st
import pandas as pd
import numpy as np
import math
from pathlib import Path
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¤–éƒ¨æ¨¡å‹æ¥å£ â”€â”€â”€â”€â”€â”€â”€â”€â”€
from models.pro_model import predict_model_pro
from models.model_pro_ensemble import predict_model_pro_ensemble
from models.predict_model_meta import predict_model_meta
from similarity_matcher import SimilarityMatcher

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ UI æ ·å¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<style>
.stApp { background:linear-gradient(135deg,#f0f8ff,#e6e6fa); }
.company-name{font-size:1.1em;font-weight:600;text-shadow:1px 1px 2px rgba(0,0,0,0.2);}
.stTextInput>div>div>input{max-width:200px;}
.stButton>button{margin-top:4px;margin-bottom:8px;}

/* gap å·®å€¼æ¨¡å¼è¡¨æ ¼ï¼šä¸¤åˆ—å¹¶æ’ã€è¡Œå†…å¯¹é½ */
.gap-table{
  width: auto;                          /* è¡¨å®½åº¦æŒ‰å†…å®¹è‡ªé€‚åº” */
  margin: 0.5rem auto 0.8rem auto;      /* å±…ä¸­ */
  border-collapse: separate;
  border-spacing: 15px 4px;             /* ä¸¤åˆ—é—´è· 15pxï¼Œè¡Œè· 4px */
}
.gap-table th{
  text-align: left;
  font-weight: 600;
  padding-bottom: 4px;
}
.gap-table td{
  padding: 2px 0;
  font-size: 0.95rem;
}
</style>
""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ åŸºæœ¬å¸¸é‡ï¼ˆäº‘ç«¯ç”¨ç›¸å¯¹è·¯å¾„ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR  = Path(__file__).parent              # å½“å‰ app.py æ‰€åœ¨ç›®å½•
DATA_FILE = BASE_DIR / "data" / "new_matches.xlsx"
HIST_PATH = BASE_DIR / "data" / "prediction_results (43).xlsx"

companies = ["Bet365", "ç«‹åš", "Interwetten", "Pinnacle", "William Hill"]
outcomes  = ["ä¸»èƒœ", "å¹³å±€", "å®¢èƒœ"]
ODDS_COLS = [f"{c}_{o}" for c in companies for o in outcomes]  # 15 åˆ—

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. è¡ç”Ÿç‰¹å¾å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€
def add_extra_features(df_odds: pd.DataFrame) -> pd.DataFrame:
    """
    ä¼ å…¥ 15 åˆ—èµ”ç‡ â†’ è¿”å›æ‹¼æ¥ 9 åˆ—æ–°ç‰¹å¾åçš„ DataFrame
    æ–°ç‰¹å¾:
        cv_home / cv_draw / cv_away
        range_home / range_draw / range_away
        p_diff (ä¸»/å®¢å¹³å‡éšå«æ¦‚ç‡å·®)
    """
    extra = pd.DataFrame(index=df_odds.index)

    mat = df_odds.values.reshape(-1, len(companies), len(outcomes))  # (N,5,3)

    cv_vals    = np.std(mat, axis=1) / np.mean(mat, axis=1)
    range_vals = np.max(mat, axis=1) - np.min(mat, axis=1)
    extra[["cv_home", "cv_draw", "cv_away"]]           = cv_vals
    extra[["range_home", "range_draw", "range_away"]] = range_vals

    inv = 1 / mat
    imp = inv / inv.sum(axis=2, keepdims=True)
    p_diff = np.abs(imp[:, :, 0].mean(axis=1) - imp[:, :, 2].mean(axis=1))
    extra["p_diff"] = p_diff

    return pd.concat(
        [df_odds.reset_index(drop=True), extra.reset_index(drop=True)],
        axis=1
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1.1 gap å·®å€¼æ¨¡å¼å·¥å…·å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _truncate_two_decimals(x: float) -> float:
    """
    åªä¿ç•™ä¸¤ä½å°æ•°ï¼Œä¸å››èˆäº”å…¥ã€‚
    ä¾‹å¦‚ï¼š0.3657 -> 0.36, 0.292 -> 0.29
    """
    try:
        x = float(x)
    except (TypeError, ValueError):
        return 0.0

    if x >= 0:
        # å‘ä¸‹æˆªæ–­ä¸¤ä½å°æ•°
        return math.floor(x * 100 + 1e-8) / 100.0
    else:
        # è‹¥å‡ºç°è´Ÿæ•°ï¼Œç”¨å‘ä¸Šå–æ•´ä¿è¯â€œæˆªæ–­â€æ•ˆæœ
        return math.ceil(x * 100 - 1e-8) / 100.0


def format_gap_pattern(values) -> str:
    """
    ä¼ å…¥é•¿åº¦ä¸º 3 çš„ gap åˆ—è¡¨ï¼Œè¿”å›å½¢å¦‚ '(3)7-4' çš„å­—ç¬¦ä¸²ã€‚
    1. æˆªæ–­ä¸ºä¸¤ä½å°æ•°ï¼›
    2. å‡åºæ’åºï¼›
    3. è®¡ç®—ç›¸é‚»å·®å€¼ *100 å¾—åˆ°æ•´æ•° d1, d2ï¼ˆä¸å››èˆäº”å…¥ï¼‰ï¼›
    4. è‹¥æœ‰ 0ï¼Œåˆ™è°ƒæ•´ä¸º '0-X'ï¼›
    5. å¤–å±‚ä¸º |d1 - d2|ã€‚
    """
    if len(values) != 3:
        return ""

    vs = sorted(_truncate_two_decimals(v) for v in values)

    d1 = int(math.floor(abs(vs[1] - vs[0]) * 100 + 1e-8))
    d2 = int(math.floor(abs(vs[2] - vs[1]) * 100 + 1e-8))

    if (d1 == 0 and d2 != 0) or (d2 == 0 and d1 != 0):
        first, second = 0, d2 if d1 == 0 else d1
    else:
        first, second = d1, d2

    outer = abs(first - second)
    return f"({outer}){first}-{second}"


def compute_gap_patterns(sims: pd.DataFrame, col: str) -> dict:
    """
    ä¸ºæŒ‡å®š gap åˆ—ï¼ˆå¦‚ 'PRO_gap' æˆ– 'PROèåˆæ¨¡å‹_gap'ï¼‰è®¡ç®—
    0-1-2, 1-2-3, 2-3-4 ä¸‰ä¸ªçª—å£çš„å·®å€¼æ¨¡å¼ã€‚
    """
    if col not in sims.columns:
        return {}

    vals = sims[col].tolist()
    windows = [("0-1-2", 0), ("1-2-3", 1), ("2-3-4", 2)]
    patterns = {}

    for label, start in windows:
        if len(vals) >= start + 3:
            triple = vals[start:start + 3]
            patterns[label] = format_gap_pattern(triple)

    return patterns

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. è®­ç»ƒå¹¶ç¼“å­˜æ¨¡å‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_models():
    if not DATA_FILE.exists():
        raise FileNotFoundError(f"DATA_FILE not found: {DATA_FILE}")

    df_raw = pd.read_excel(DATA_FILE)
    X_base = df_raw[ODDS_COLS]
    X_feat = add_extra_features(X_base)          # 15+9 = 24 åˆ—
    feat_cols = X_feat.columns.tolist()

    # éšå«æ¦‚ç‡æ›¿æ¢ (ä»…å‰ 15 åˆ—èµ”ç‡)
    X_imp = X_feat.copy().values.astype(float)
    for j in range(0, 15, 3):
        inv = 1 / X_imp[:, j:j+3]
        X_imp[:, j:j+3] = inv / inv.sum(axis=1, keepdims=True)

    y = df_raw["æ¯”èµ›ç»“æœ"].map({"ä¸»èƒœ": 0, "å¹³å±€": 1, "å®¢èƒœ": 2}).values

    # â€”â€” Draw äºŒåˆ†ç±» â€”â€” #
    y_draw = (y == 1).astype(int)
    draw_hgb = HistGradientBoostingClassifier(
        learning_rate=0.01, max_depth=5, loss="log_loss", random_state=42
    ).fit(X_imp, y_draw)
    draw_tree = DecisionTreeClassifier(max_depth=3, random_state=42).fit(X_imp, y_draw)

    # â€”â€” Win-Lose äºŒåˆ†ç±» â€”â€” #
    mask = (y != 1)
    X_wl, y_wl = X_imp[mask], (y[mask] == 0).astype(int)
    winlose_hgb = HistGradientBoostingClassifier(
        learning_rate=0.01, max_depth=5, loss="log_loss", random_state=42
    ).fit(X_wl, y_wl)

    # â€”â€” å¤‡ç”¨å¤šåˆ†ç±» (å¹³å±€æƒé‡ 0.8) â€”â€” #
    class_w = {0: 1.0, 1: 0.8, 2: 1.0}
    samp_w  = np.array([class_w[yi] for yi in y])
    multi_clf = HistGradientBoostingClassifier(
        learning_rate=0.01, max_depth=5, loss="log_loss", random_state=42
    ).fit(X_imp, y, sample_weight=samp_w)

    return feat_cols, draw_hgb, draw_tree, winlose_hgb, multi_clf

feat_cols, draw_hgb, draw_tree, winlose_hgb, multi_clf = load_models()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. Streamlit é¡µé¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="CV/Range/Pdiff Boost é¢„æµ‹", layout="wide")
st.title("âš½è¶³çƒé¢„æµ‹ç³»ç»Ÿ")

# Session State
if "input_df" not in st.session_state:
    st.session_state.input_df = pd.DataFrame(columns=ODDS_COLS)
if "matcher" not in st.session_state:
    if not HIST_PATH.exists():
        raise FileNotFoundError(f"HIST_PATH not found: {HIST_PATH}")
    st.session_state.matcher = SimilarityMatcher(str(HIST_PATH))
if "pattern_records" not in st.session_state:
    # ç”¨äºä¿å­˜æ¯åœºæ¯”èµ›çš„ 6 ä¸ªå·®å€¼æ¨¡å¼ï¼ˆå¯¼å‡ºç”¨ï¼‰
    st.session_state.pattern_records = []

# ---------- æ•°æ®è¾“å…¥ ----------
mode = st.radio("ğŸ“¥ æ•°æ®è¾“å…¥æ–¹å¼", ["ä¸Šä¼ æ–‡ä»¶", "æ‰‹åŠ¨å½•å…¥"], horizontal=True)

if mode == "ä¸Šä¼ æ–‡ä»¶":
    up = st.file_uploader("ä¸Šä¼ èµ”ç‡æ–‡ä»¶ (Excel/CSVï¼Œæ¯è¡Œ15åˆ—)", type=["xlsx", "csv"])
    if up is not None:
        df_up = pd.read_csv(up) if up.name.endswith(".csv") else pd.read_excel(up)
        st.session_state.input_df = df_up[ODDS_COLS]
        st.session_state.pattern_records = []   # è¾“å…¥å˜äº†ï¼Œæ¸…ç©ºå·²æœ‰æ¨¡å¼è®°å½•
        st.success(f"âœ… å·²è¯»å– {len(df_up)} åœºæ¯”èµ›")
        st.dataframe(st.session_state.input_df)

else:
    st.subheader("ğŸ–Š æ‰‹åŠ¨å½•å…¥ (é€å…¬å¸ä¸€è¡Œ)")
    with st.form("manual", clear_on_submit=True):
        inps = {}
        for comp in companies:
            c1, c2 = st.columns([1, 2])
            c1.markdown(f"<div class='company-name'>{comp}</div>", unsafe_allow_html=True)
            inps[comp] = c2.text_input(
                "", placeholder="2.05 3.60 3.50", key=f"man_{comp}"
            )
        if st.form_submit_button("æ·»åŠ æ¯”èµ›"):
            row, ok = [], True
            for comp in companies:
                parts = inps[comp].split()
                if len(parts) != 3:
                    st.error(f"{comp} éœ€è¾“å…¥ 3 ä¸ªèµ”ç‡")
                    ok = False
                    break
                row += [float(x) for x in parts]
            if ok:
                st.session_state.input_df = pd.concat(
                    [st.session_state.input_df,
                     pd.DataFrame([row], columns=ODDS_COLS)],
                    ignore_index=True
                )
                st.session_state.pattern_records = []   # æœ‰æ–°æ¯”èµ›ï¼Œæ¸…ç©ºæ—§æ¨¡å¼è®°å½•
                st.success("âœ… å·²æ·»åŠ 1åœºæ¯”èµ›")

# ---------- å†å²åŒ¹é… ----------
if not st.session_state.input_df.empty:
    st.subheader("ğŸ” å†å²ç›¸ä¼¼æ¯”èµ›æ¨è")
    df_pro    = predict_model_pro(st.session_state.input_df)
    prob_cols = [c for c in df_pro.columns if c.startswith("P(")]
    for pc in prob_cols:
        df_pro[pc].fillna(0, inplace=True)

    ens_in = pd.concat(
        [
            st.session_state.input_df.reset_index(drop=True),
            df_pro[["average_gap"] + prob_cols].reset_index(drop=True),
        ],
        axis=1,
    )

    try:
        df_ens = predict_model_pro_ensemble(ens_in)
    except Exception:
        df_ens = pd.DataFrame({
            "PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ": ["å¹³å±€"] * len(df_pro),
            "PROèåˆæ¨¡å‹_gap": [0.0] * len(df_pro),
        })

    try:
        df_meta = predict_model_meta(st.session_state.input_df)
    except Exception:
        df_meta = pd.DataFrame()

    # æ¯æ¬¡é‡æ–°è·‘å†å²åŒ¹é…å‰ï¼Œæ¸…ç©º pattern_recordsï¼Œé¿å…æ®‹ç•™æ—§ç»“æœ
    st.session_state.pattern_records = []

    # æ¨¡å¼åˆ—åï¼ˆæ¥è‡ª gap_patterns_export.csvï¼‰
    pattern_cols_pro = [
        "PRO_pattern_0_1_2",
        "PRO_pattern_1_2_3",
        "PRO_pattern_2_3_4",
    ]
    pattern_cols_ens = [
        "ENS_pattern_0_1_2",
        "ENS_pattern_1_2_3",
        "ENS_pattern_2_3_4",
    ]

    for i in range(len(st.session_state.input_df)):
        # 1) ç¬¬ä¸€å±‚ï¼šæŒ‰ PRO_gap / PROèåˆ_gap / èåˆä¿¡å¿ƒ / æ¨èæ€»åˆ† åšç›¸ä¼¼åŒ¹é…
        q = {
            "PRO_gap": df_pro.loc[i, "average_gap"],
            "PROèåˆæ¨¡å‹_gap": df_ens.loc[i, "PROèåˆæ¨¡å‹_gap"],
            "èåˆä¿¡å¿ƒ": df_meta.loc[i, "èåˆä¿¡å¿ƒ"] if "èåˆä¿¡å¿ƒ" in df_meta else 0,
            "æ¨èæ€»åˆ†": df_meta.loc[i, "æ¨èæ€»åˆ†"] if "æ¨èæ€»åˆ†" in df_meta else 0,
            "pair": f"{df_pro.loc[i,'æœ€ç»ˆé¢„æµ‹ç»“æœ']}-{df_ens.loc[i,'PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ']}",
        }
        try:
            sims = st.session_state.matcher.query(q, k=5)
        except Exception:
            sims = pd.DataFrame()

        st.markdown(f"**ç¬¬ {i+1} åœº** å†å²ç›¸ä¼¼æ¯”èµ›ï¼š")

        # ä¿è¯æ¨èç¼–å·å°±æ˜¯ 0ã€1ã€2ã€3ã€4
        sims = sims.reset_index(drop=True)

        # ===== è®¡ç®—å½“å‰æ¯”èµ›çš„ 6 ä¸ªæ¨¡å¼ï¼ˆåŸºäºè¿™ 5 åœºç›¸ä¼¼æ¯”èµ›ï¼‰ =====
        pro_patterns = compute_gap_patterns(sims, "PRO_gap")
        ens_patterns = compute_gap_patterns(sims, "PROèåˆæ¨¡å‹_gap")

        pro0 = pro_patterns.get("0-1-2", "")
        pro1 = pro_patterns.get("1-2-3", "")
        pro2 = pro_patterns.get("2-3-4", "")

        ens0 = ens_patterns.get("0-1-2", "")
        ens1 = ens_patterns.get("1-2-3", "")
        ens2 = ens_patterns.get("2-3-4", "")

        # ===== åŸºäº 6 ä¸ªæ¨¡å¼ï¼Œæ‰“â€œå¼ºå‚è€ƒâ€æ ‡è®° =====
        if not sims.empty and all(
            col in sims.columns for col in pattern_cols_pro + pattern_cols_ens
        ):
            # å¤„ç†ç¼ºå¤±å€¼ä¸º ""ï¼Œæ–¹ä¾¿å­—ç¬¦ä¸²å¯¹æ¯”
            for col in pattern_cols_pro + pattern_cols_ens:
                sims[col] = sims[col].fillna("")

            match_counts = []
            match_levels = []
            strong_flags  = []

            for _, row in sims.iterrows():
                cnt = 0
                if pro0 and row["PRO_pattern_0_1_2"] == pro0:
                    cnt += 1
                if pro1 and row["PRO_pattern_1_2_3"] == pro1:
                    cnt += 1
                if pro2 and row["PRO_pattern_2_3_4"] == pro2:
                    cnt += 1
                if ens0 and row["ENS_pattern_0_1_2"] == ens0:
                    cnt += 1
                if ens1 and row["ENS_pattern_1_2_3"] == ens1:
                    cnt += 1
                if ens2 and row["ENS_pattern_2_3_4"] == ens2:
                    cnt += 1

                match_counts.append(cnt)
                if cnt == 6:
                    level = "å®Œå…¨åŒ¹é…"
                    strong = True
                elif cnt >= 4:
                    level = "åŸºæœ¬åŒ¹é…"
                    strong = True
                elif cnt >= 1:
                    level = "éƒ¨åˆ†åŒ¹é…"
                    strong = False
                else:
                    level = "ä¸åŒ¹é…"
                    strong = False

                match_levels.append(level)
                strong_flags.append(strong)

            sims["æ¨¡å¼åŒ¹é…ä¸ªæ•°"] = match_counts
            sims["æ¨¡å¼åŒ¹é…ç¨‹åº¦"] = match_levels
            sims["å¼ºå‚è€ƒ"]      = strong_flags
            sims["å¼ºå‚è€ƒæ ‡è®°"]   = sims["å¼ºå‚è€ƒ"].map(
                lambda x: "â­ å¼ºå‚è€ƒ" if x else ""
            )
        else:
            sims["æ¨¡å¼åŒ¹é…ä¸ªæ•°"] = 0
            sims["æ¨¡å¼åŒ¹é…ç¨‹åº¦"] = "æœªæä¾›æ¨¡å¼"
            sims["å¼ºå‚è€ƒ"]      = False
            sims["å¼ºå‚è€ƒæ ‡è®°"]   = ""

        # å±•ç¤ºç›¸ä¼¼æ¯”èµ›è¡¨ï¼ˆåŒ…å«â€œå¼ºå‚è€ƒâ€åˆ—ï¼‰
        st.dataframe(sims, use_container_width=True)

        # ===== ä¸¤ä¸ªæ¨¡å‹çš„å·®å€¼æ¨¡å¼ï¼Œä¸¤åˆ—è¡¨æ ¼æ–¹å¼å¹¶æ’ä¸”çºµå‘å¯¹é½ï¼ˆå½“å‰æ¯”èµ›è‡ªèº«çš„æ¨¡å¼ï¼‰ =====
        if pro0 or pro1 or pro2 or ens0 or ens1 or ens2:
            html = f"""
<table class="gap-table">
  <tr>
    <th>PRO_gap å·®å€¼æ¨¡å¼</th>
    <th>PROèåˆæ¨¡å‹_gap å·®å€¼æ¨¡å¼</th>
  </tr>
  <tr>
    <td>{pro0}</td>
    <td>{ens0}</td>
  </tr>
  <tr>
    <td>{pro1}</td>
    <td>{ens1}</td>
  </tr>
  <tr>
    <td>{pro2}</td>
    <td>{ens2}</td>
  </tr>
</table>
"""
            st.markdown(html, unsafe_allow_html=True)

        # ä¿å­˜å¯¼å‡ºè®°å½•ï¼šæ¯åœºæ¯”èµ› 6 ä¸ªæ¨¡å¼
        st.session_state.pattern_records.append({
            "æ¯”èµ›ç¼–å·": i + 1,
            "PRO_pattern_0_1_2": pro0,
            "PRO_pattern_1_2_3": pro1,
            "PRO_pattern_2_3_4": pro2,
            "ENS_pattern_0_1_2": ens0,
            "ENS_pattern_1_2_3": ens1,
            "ENS_pattern_2_3_4": ens2,
        })

    # â€”â€” å·®å€¼æ¨¡å¼å¯¼å‡ºåŒºåŸŸ â€”â€” #
    if st.session_state.pattern_records:
        df_patterns = pd.DataFrame(st.session_state.pattern_records).sort_values("æ¯”èµ›ç¼–å·")
        st.subheader("ğŸ“¤ å·®å€¼æ¨¡å¼å¯¼å‡ºï¼ˆæ¯åœºæ¯”èµ›çš„ PRO / PROèåˆ å·®å€¼æ¨¡å¼ï¼‰")
        st.dataframe(df_patterns, use_container_width=True)
        st.download_button(
            "â¬‡ï¸ ä¸‹è½½å·®å€¼æ¨¡å¼ï¼ˆCSVï¼‰",
            df_patterns.to_csv(index=False).encode("utf-8-sig"),
            "gap_patterns_export.csv",
            "text/csv",
        )

# ---------- é¢„æµ‹ ----------
if not st.session_state.input_df.empty and st.button("ğŸ¯ è¿è¡Œé¢„æµ‹"):
    df_odds  = st.session_state.input_df.copy()
    X_feat   = add_extra_features(df_odds)                # 15+9 åˆ—
    X_imp    = X_feat.values.astype(float)
    for j in range(0, 15, 3):                             # ä»…èµ”ç‡åˆ—åšéšå«æ¦‚ç‡
        inv = 1 / X_imp[:, j:j+3]
        X_imp[:, j:j+3] = inv / inv.sum(axis=1, keepdims=True)

    # â€”â€” 1) Draw â€”â€” #
    p_draw = (
        0.6 * draw_hgb.predict_proba(X_imp)[:, 1]
        + 0.4 * draw_tree.predict_proba(X_imp)[:, 1]
    )
    p_draw = np.clip(p_draw + 0.10 * np.power(1 - p_draw, 0.50), 0, 1)

    # â€”â€” 2) Win-Lose â€”â€” #
    p_wl   = winlose_hgb.predict_proba(X_imp)
    p_base = np.zeros((len(X_imp), 3))
    p_base[:, 1] = p_draw
    p_base[:, 0] = p_wl[:, 1] * (1 - p_draw)
    p_base[:, 2] = p_wl[:, 0] * (1 - p_draw)

    # â€”â€” 3) PRO / Ensemble â€”â€” #
    df_pro  = predict_model_pro(df_odds)
    prob2   = [c for c in df_pro.columns if c.startswith("P(")]
    for pc in prob2:
        df_pro[pc].fillna(0, inplace=True)

    ens_in  = pd.concat(
        [df_odds.reset_index(drop=True),
         df_pro[["average_gap"] + prob2].reset_index(drop=True)],
        axis=1,
    )
    try:
        df_ens = predict_model_pro_ensemble(ens_in)
        p_ens  = df_ens[[f"P({o})" for o in outcomes]].values
    except Exception:
        p_ens = np.zeros_like(p_base)

    # â€”â€” 4) META â€”â€” #
    try:
        df_meta = predict_model_meta(df_odds)
        p_meta  = df_meta[[f"P({o})" for o in outcomes]].values
    except Exception:
        p_meta = np.zeros_like(p_base)

    # â€”â€” 5) Multi â€”â€” #
    p_multi = multi_clf.predict_proba(X_imp)

    # â€”â€” 6) äº”è·¯èåˆ â€”â€”  â¬…ï¸ ç”¨â€œå››æƒé‡â€æ›¿æ¢å‡å€¼
    w_base, w_ens, w_meta, w_multi = 0.10, 0.70, 0.10, 0.00
    wsum   = w_base + w_ens + w_meta + w_multi          # =1.0

    p_final = (
        w_base  * p_base
        + w_ens * p_ens
        + w_meta * p_meta
        + w_multi * p_multi
    ) / wsum

    p_final /= p_final.sum(axis=1, keepdims=True)        # å½’ä¸€åŒ–

    preds = [outcomes[k] for k in p_final.argmax(axis=1)]
    df_res = pd.DataFrame(p_final * 100, columns=[f"{o}(%)" for o in outcomes])
    df_res.insert(0, "æœ€ç»ˆé¢„æµ‹", preds)
    df_res.index = np.arange(1, len(df_res) + 1)
    df_res.index.name = "æ¯”èµ›ç¼–å·"

    st.subheader("ğŸ“Š ç»¼åˆæ¨¡å‹é¢„æµ‹ç»“æœ")
    st.dataframe(df_res, use_container_width=True)
    st.download_button(
        "â¬‡ï¸ ä¸‹è½½ç»“æœ",
        df_res.to_csv(index=True).encode("utf-8-sig"),
        "predictions.csv",
        "text/csv",
    )
