# app.py  â€“  äº‘ç«¯ & æœ¬åœ°ç»Ÿä¸€ç‰ˆ + ç³»ç»Ÿæ¨èé€»è¾‘ï¼ˆé˜ˆå€¼ 0.03ï¼‰
# åŠŸèƒ½ï¼š
# - CV / Range / Pdiff ç‰¹å¾
# - å†å²ç›¸ä¼¼æ¯”èµ›æ¨èï¼ˆæ²¿ç”¨åŸé€»è¾‘ï¼‰
# - åŸºäº5åœºç›¸ä¼¼æ¯”èµ›è®¡ç®—å½“å‰æ¯”èµ›çš„6ä¸ªæ¨¡å¼ï¼ˆPRO / PROèåˆï¼‰
# - ä½¿ç”¨6ä¸ªæ¨¡å¼å•ç‹¬åŒ¹é…å…¨åº“ï¼ˆæ¨¡å¼åŒ¹é…å‚è€ƒï¼‰
# - ç³»ç»Ÿæ¨èç»“æœï¼ˆä¸»é€‰ + å¤‡é€‰ï¼Œé˜ˆå€¼=0.03ï¼‰
# - å¯¼å‡ºæ–°æ¯”èµ›çš„æ¨¡å¼

import streamlit as st
import pandas as pd
import numpy as np
import math
from pathlib import Path
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¤–éƒ¨æ¨¡å‹æ¥å£ â”€â”€â”€â”€â”€â”€â”€â”€â”€
from models.pro_model import predict_model_pro
from models.model_pro_ensemble import predict_model_pro_ensemble
from models.predict_model_meta import predict_model_meta
from similarity_matcher import SimilarityMatcher

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ UI æ ·å¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="CV/Range/Pdiff Boost é¢„æµ‹", layout="wide")

st.markdown("""
<style>
.stApp { background:linear-gradient(135deg,#f0f8ff,#e6e6fa); }
.company-name{font-size:1.1em;font-weight:600;text-shadow:1px 1px 2px rgba(0,0,0,0.2);}
.stTextInput>div>div>input{max-width:200px;}
.stButton>button{margin-top:4px;margin-bottom:8px;}

/* gap å·®å€¼æ¨¡å¼è¡¨æ ¼ï¼šä¸¤åˆ—å¹¶æ’ã€è¡Œå†…å¯¹é½ */
.gap-table{
  width: auto;
  margin: 0.5rem auto 0.8rem auto;
  border-collapse: separate;
  border-spacing: 15px 4px;
}
.gap-table th{
  text-align: left;
  font-weight: 600;
  padding-bottom: 4px;
}
.gap-table td{
  padding: 2px 0;
  font-size: 0.95rem;
}
</style>
""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ åŸºæœ¬å¸¸é‡ï¼ˆç›¸å¯¹è·¯å¾„ï¼Œäº‘ç«¯ & æœ¬åœ°ç»Ÿä¸€ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR  = Path(__file__).parent
DATA_FILE = BASE_DIR / "data" / "new_matches.xlsx"
HIST_PATH = BASE_DIR / "data" / "prediction_results (43).xlsx"

companies = ["Bet365","ç«‹åš","Interwetten","Pinnacle","William Hill"]
outcomes  = ["ä¸»èƒœ","å¹³å±€","å®¢èƒœ"]
ODDS_COLS = [f"{c}_{o}" for c in companies for o in outcomes]  # 15 åˆ—
OUTCOME_COL = "æ¯”èµ›ç»“æœ"  # å†å²åº“ä¸­çœŸå®ç»“æœåˆ—å

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. è¡ç”Ÿç‰¹å¾å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€
def add_extra_features(df_odds: pd.DataFrame) -> pd.DataFrame:
    extra = pd.DataFrame(index=df_odds.index)

    mat = df_odds.values.reshape(-1, len(companies), len(outcomes))  # (N,5,3)

    cv_vals    = np.std(mat, axis=1) / np.mean(mat, axis=1)
    range_vals = np.max(mat, axis=1) - np.min(mat, axis=1)
    extra[["cv_home","cv_draw","cv_away"]]           = cv_vals
    extra[["range_home","range_draw","range_away"]] = range_vals

    inv = 1 / mat
    imp = inv / inv.sum(axis=2, keepdims=True)
    p_diff = np.abs(imp[:,:,0].mean(axis=1) - imp[:,:,2].mean(axis=1))
    extra["p_diff"] = p_diff

    return pd.concat(
        [df_odds.reset_index(drop=True), extra.reset_index(drop=True)],
        axis=1
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1.1 gap å·®å€¼æ¨¡å¼å·¥å…·å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _truncate_two_decimals(x: float) -> float:
    try:
        x = float(x)
    except (TypeError, ValueError):
        return 0.0
    if x >= 0:
        return math.floor(x * 100 + 1e-8) / 100.0
    else:
        return math.ceil(x * 100 - 1e-8) / 100.0


def format_gap_pattern(values) -> str:
    if len(values) != 3:
        return ""
    vs = sorted(_truncate_two_decimals(v) for v in values)
    d1 = int(math.floor(abs(vs[1] - vs[0]) * 100 + 1e-8))
    d2 = int(math.floor(abs(vs[2] - vs[1]) * 100 + 1e-8))

    if (d1 == 0 and d2 != 0) or (d2 == 0 and d1 != 0):
        first, second = 0, d2 if d1 == 0 else d1
    else:
        first, second = d1, d2

    outer = abs(first - second)
    return f"({outer}){first}-{second}"


def compute_gap_patterns(sims: pd.DataFrame, col: str) -> dict:
    if col not in sims.columns:
        return {}
    vals = sims[col].tolist()
    windows = [("0-1-2", 0), ("1-2-3", 1), ("2-3-4", 2)]
    patterns = {}
    for label, start in windows:
        if len(vals) >= start + 3:
            triple = vals[start:start+3]
            patterns[label] = format_gap_pattern(triple)
    return patterns

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1.2 ç³»ç»Ÿæ¨èé€»è¾‘ï¼ˆå•åœºï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def system_total_scores_for_match(
    i: int,
    df_pro: pd.DataFrame,
    df_ens: pd.DataFrame,
    sims_basic: pd.DataFrame,
    sims_pattern: pd.DataFrame,
    outcome_col: str = OUTCOME_COL,
) -> dict:
    """
    å¯¹ç¬¬ i åœºæ¯”èµ›ï¼Œè®¡ç®—â€œç³»ç»Ÿæ¨èé€»è¾‘â€ä¸‹æ¯ä¸ªç»“æœï¼ˆä¸»èƒœ/å¹³å±€/å®¢èƒœï¼‰çš„ç»¼åˆå¾—åˆ†ã€‚
    é€»è¾‘ä¸ä½ è¯„ä¼°è„šæœ¬ä¸€è‡´ï¼šæ¨¡å‹ + å†å²ç›¸ä¼¼ + æ¨¡å¼å¼ºå‚è€ƒã€‚
    """
    # 1) æ¨¡å‹åˆ†æ•°ï¼š0.4 * PRO + 0.6 * PROèåˆ
    model_score = {o: 0.0 for o in outcomes}
    for o in outcomes:
        p_pro = df_pro.loc[i, f"P({o})"] if f"P({o})" in df_pro.columns else 0.0
        p_ens = 0.0
        if df_ens is not None and f"P({o})" in df_ens.columns:
            p_ens = df_ens.loc[i, f"P({o})"]
        model_score[o] = 0.4 * float(p_pro) + 0.6 * float(p_ens)

    # 2) å†å²ç›¸ä¼¼æ¯”èµ›æŠ•ç¥¨ï¼ˆsims_basicï¼Œä¸€èˆ¬5åœºï¼‰
    hist_basic_votes = {o: 0.0 for o in outcomes}
    if not sims_basic.empty and outcome_col in sims_basic.columns:
        for idx, row in sims_basic.iterrows():
            res = str(row[outcome_col])
            if res in hist_basic_votes:
                hist_basic_votes[res] += 1.0 / (1.0 + idx)  # 1, 1/2, 1/3...

    max_basic = max(hist_basic_votes.values()) if any(hist_basic_votes.values()) else 1.0
    hist_basic_score = {o: (hist_basic_votes[o] / max_basic) for o in outcomes}

    # 3) æ¨¡å¼åŒ¹é…å‚è€ƒæŠ•ç¥¨ï¼ˆåªç”¨å¼ºå‚è€ƒè¡Œï¼‰
    hist_pattern_votes = {o: 0.0 for o in outcomes}
    if not sims_pattern.empty and outcome_col in sims_pattern.columns:
        for idx, row in sims_pattern.iterrows():
            if not bool(row.get("å¼ºå‚è€ƒ", False)):
                continue
            res = str(row[outcome_col])
            if res in hist_pattern_votes:
                hist_pattern_votes[res] += 1.0 / (1.0 + idx)

    max_pattern = max(hist_pattern_votes.values()) if any(hist_pattern_votes.values()) else 1.0
    hist_pattern_score = {o: (hist_pattern_votes[o] / max_pattern) for o in outcomes}

    # 4) ç»¼åˆå¾—åˆ†ï¼ˆä¸ä½ è¯„ä¼°è„šæœ¬ä¸€è‡´çš„æƒé‡ï¼‰
    w_model   = 0.5
    w_basic   = 0.3
    w_pattern = 0.2

    total_score = {}
    for o in outcomes:
        total_score[o] = (
            w_model   * model_score[o] +
            w_basic   * hist_basic_score[o] +
            w_pattern * hist_pattern_score[o]
        )

    return total_score


def system_recommendation_for_match(
    i: int,
    df_pro: pd.DataFrame,
    df_ens: pd.DataFrame,
    sims_basic: pd.DataFrame,
    sims_pattern: pd.DataFrame,
    outcome_col: str = OUTCOME_COL,
    threshold: float = 0.03,  # å•/åŒé€‰é˜ˆå€¼
) -> dict:
    """
    åŸºäº total_score + é˜ˆå€¼ï¼Œç»™å‡ºï¼š
        - ä¸»é€‰
        - å¤‡é€‰ï¼ˆè‹¥å·®å€¼ < é˜ˆå€¼ï¼‰
        - total_score å­—å…¸
    """
    total_score = system_total_scores_for_match(
        i=i,
        df_pro=df_pro,
        df_ens=df_ens,
        sims_basic=sims_basic,
        sims_pattern=sims_pattern,
        outcome_col=outcome_col,
    )

    ordered = sorted(outcomes, key=lambda o: total_score[o], reverse=True)
    best   = ordered[0]
    second = ordered[1]

    diff = total_score[best] - total_score[second]
    if diff < threshold:
        backup = second
    else:
        backup = None

    return {
        "ä¸»é€‰": best,
        "å¤‡é€‰": backup,
        "total_score": total_score,
    }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. è®­ç»ƒå¹¶ç¼“å­˜æ¨¡å‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_models():
    if not DATA_FILE.exists():
        raise FileNotFoundError(f"DATA_FILE not found: {DATA_FILE}")
    df_raw = pd.read_excel(DATA_FILE)
    X_base = df_raw[ODDS_COLS]
    X_feat = add_extra_features(X_base)          # 15+9 = 24 åˆ—
    feat_cols = X_feat.columns.tolist()

    X_imp = X_feat.copy().values.astype(float)
    for j in range(0, 15, 3):
        inv = 1 / X_imp[:, j:j+3]
        X_imp[:, j:j+3] = inv / inv.sum(axis=1, keepdims=True)

    y = df_raw["æ¯”èµ›ç»“æœ"].map({"ä¸»èƒœ":0,"å¹³å±€":1,"å®¢èƒœ":2}).values

    y_draw = (y == 1).astype(int)
    draw_hgb = HistGradientBoostingClassifier(
        learning_rate=0.01,max_depth=5,loss="log_loss",random_state=42
    ).fit(X_imp, y_draw)
    draw_tree = DecisionTreeClassifier(max_depth=3,random_state=42).fit(X_imp, y_draw)

    mask = (y != 1)
    X_wl, y_wl = X_imp[mask], (y[mask] == 0).astype(int)
    winlose_hgb = HistGradientBoostingClassifier(
        learning_rate=0.01,max_depth=5,loss="log_loss",random_state=42
    ).fit(X_wl, y_wl)

    class_w = {0:1.0, 1:0.8, 2:1.0}
    samp_w  = np.array([class_w[yi] for yi in y])
    multi_clf = HistGradientBoostingClassifier(
        learning_rate=0.01,max_depth=5,loss="log_loss",random_state=42
    ).fit(X_imp, y, sample_weight=samp_w)

    return feat_cols, draw_hgb, draw_tree, winlose_hgb, multi_clf

feat_cols, draw_hgb, draw_tree, winlose_hgb, multi_clf = load_models()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. Streamlit é¡µé¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("âš½è¶³çƒé¢„æµ‹ç³»ç»Ÿ")

if "input_df" not in st.session_state:
    st.session_state.input_df = pd.DataFrame(columns=ODDS_COLS)
if "matcher" not in st.session_state:
    if not HIST_PATH.exists():
        st.error(f"æ‰¾ä¸åˆ°å†å²ç»“æœæ–‡ä»¶ï¼š{HIST_PATH}")
    else:
        st.session_state.matcher = SimilarityMatcher(str(HIST_PATH))
if "pattern_records" not in st.session_state:
    st.session_state.pattern_records = []

# ---------- æ•°æ®è¾“å…¥ ----------
mode = st.radio("ğŸ“¥ æ•°æ®è¾“å…¥æ–¹å¼", ["ä¸Šä¼ æ–‡ä»¶","æ‰‹åŠ¨å½•å…¥"], horizontal=True)

if mode == "ä¸Šä¼ æ–‡ä»¶":
    up = st.file_uploader("ä¸Šä¼ èµ”ç‡æ–‡ä»¶ (Excel/CSVï¼Œæ¯è¡Œ15åˆ—)", type=["xlsx","csv"])
    if up is not None:
        df_up = pd.read_csv(up) if up.name.endswith(".csv") else pd.read_excel(up)
        st.session_state.input_df = df_up[ODDS_COLS]
        st.session_state.pattern_records = []
        st.success(f"âœ… å·²è¯»å– {len(df_up)} åœºæ¯”èµ›")
        st.dataframe(st.session_state.input_df)

else:
    st.subheader("ğŸ–Š æ‰‹åŠ¨å½•å…¥ (é€å…¬å¸ä¸€è¡Œ)")
    with st.form("manual", clear_on_submit=True):
        inps = {}
        for comp in companies:
            c1,c2 = st.columns([1,2])
            c1.markdown(f"<div class='company-name'>{comp}</div>", unsafe_allow_html=True)
            inps[comp] = c2.text_input("", placeholder="2.05 3.60 3.50", key=f"man_{comp}")
        if st.form_submit_button("æ·»åŠ æ¯”èµ›"):
            row, ok = [], True
            for comp in companies:
                parts = inps[comp].split()
                if len(parts)!=3:
                    st.error(f"{comp} éœ€è¾“å…¥ 3 ä¸ªèµ”ç‡"); ok=False; break
                row += [float(x) for x in parts]
            if ok:
                st.session_state.input_df = pd.concat(
                    [st.session_state.input_df,
                     pd.DataFrame([row], columns=ODDS_COLS)],
                    ignore_index=True
                )
                st.session_state.pattern_records = []
                st.success("âœ… å·²æ·»åŠ 1åœºæ¯”èµ›")

# ---------- å†å²åŒ¹é… + æ¨¡å¼åŒ¹é…å‚è€ƒ + ç³»ç»Ÿæ¨è ----------
if not st.session_state.input_df.empty and "matcher" in st.session_state:
    st.subheader("ğŸ” å†å²ç›¸ä¼¼æ¯”èµ›æ¨è & æ¨¡å¼åŒ¹é…å‚è€ƒ & ç³»ç»Ÿæ¨è")

    df_pro    = predict_model_pro(st.session_state.input_df)
    prob_cols = [c for c in df_pro.columns if c.startswith("P(")]
    for pc in prob_cols: df_pro[pc].fillna(0, inplace=True)

    ens_in = pd.concat([
        st.session_state.input_df.reset_index(drop=True),
        df_pro[["average_gap"] + prob_cols].reset_index(drop=True)
    ], axis=1)
    try:
        df_ens = predict_model_pro_ensemble(ens_in)
    except:
        df_ens = pd.DataFrame({
            "PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ": ["å¹³å±€"]*len(df_pro),
            "PROèåˆæ¨¡å‹_gap": [0.0]*len(df_pro)
        })
    try:
        df_meta = predict_model_meta(st.session_state.input_df)
    except:
        df_meta = pd.DataFrame()

    st.session_state.pattern_records = []

    for i in range(len(st.session_state.input_df)):
        st.markdown(f"### â–¶ ç¬¬ {i+1} åœº")

        # 1) å†å²ç›¸ä¼¼æ¯”èµ›æ¨èï¼ˆåŸé€»è¾‘ï¼‰
        q_basic = {
            "PRO_gap": df_pro.loc[i,"average_gap"],
            "PROèåˆæ¨¡å‹_gap": df_ens.loc[i,"PROèåˆæ¨¡å‹_gap"],
            "èåˆä¿¡å¿ƒ": df_meta.loc[i,"èåˆä¿¡å¿ƒ"] if "èåˆä¿¡å¿ƒ" in df_meta else 0,
            "æ¨èæ€»åˆ†": df_meta.loc[i,"æ¨èæ€»åˆ†"] if "æ¨èæ€»åˆ†" in df_meta else 0,
            "pair": f"{df_pro.loc[i,'æœ€ç»ˆé¢„æµ‹ç»“æœ']}-{df_ens.loc[i,'PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ']}"
        }
        try:
            sims_basic = st.session_state.matcher.query(q_basic, k=5)
        except Exception as e:
            st.warning(f"å†å²åŒ¹é…è°ƒç”¨å‡ºé”™ï¼š{e}")
            sims_basic = pd.DataFrame()

        st.markdown("**1ï¸âƒ£ å†å²ç›¸ä¼¼æ¯”èµ›ï¼ˆåŸé€»è¾‘ï¼‰**")
        sims_basic = sims_basic.reset_index(drop=True)
        st.dataframe(sims_basic, use_container_width=True)

        # 2) ç”¨è¿™5åœºç®—å½“å‰æ¯”èµ›çš„6ä¸ªæ¨¡å¼
        pro_patterns = compute_gap_patterns(sims_basic, "PRO_gap")
        ens_patterns = compute_gap_patterns(sims_basic, "PROèåˆæ¨¡å‹_gap")

        pro0 = pro_patterns.get("0-1-2", "")
        pro1 = pro_patterns.get("1-2-3", "")
        pro2 = pro_patterns.get("2-3-4", "")

        ens0 = ens_patterns.get("0-1-2", "")
        ens1 = ens_patterns.get("1-2-3", "")
        ens2 = ens_patterns.get("2-3-4", "")

        if pro0 or pro1 or pro2 or ens0 or ens1 or ens2:
            st.markdown("**2ï¸âƒ£ å½“å‰æ¯”èµ›çš„ PRO / PROèåˆ å·®å€¼æ¨¡å¼**")
            html = f"""
<table class="gap-table">
  <tr>
    <th>PRO_gap å·®å€¼æ¨¡å¼</th>
    <th>PROèåˆæ¨¡å‹_gap å·®å€¼æ¨¡å¼</th>
  </tr>
  <tr>
    <td>{pro0}</td>
    <td>{ens0}</td>
  </tr>
  <tr>
    <td>{pro1}</td>
    <td>{ens1}</td>
  </tr>
  <tr>
    <td>{pro2}</td>
    <td>{ens2}</td>
  </tr>
</table>
"""
            st.markdown(html, unsafe_allow_html=True)

        st.session_state.pattern_records.append({
            "æ¯”èµ›ç¼–å·": i+1,
            "PRO_pattern_0_1_2": pro0,
            "PRO_pattern_1_2_3": pro1,
            "PRO_pattern_2_3_4": pro2,
            "ENS_pattern_0_1_2": ens0,
            "ENS_pattern_1_2_3": ens1,
            "ENS_pattern_2_3_4": ens2,
        })

        # 3) æ¨¡å¼åŒ¹é…å‚è€ƒï¼šåªåŸºäº6ä¸ªæ¨¡å¼å­—æ®µåŒ¹é…å…¨åº“
        q_pattern = {
            "PRO_pattern_0_1_2": pro0,
            "PRO_pattern_1_2_3": pro1,
            "PRO_pattern_2_3_4": pro2,
            "ENS_pattern_0_1_2": ens0,
            "ENS_pattern_1_2_3": ens1,
            "ENS_pattern_2_3_4": ens2,
        }
        try:
            sims_pattern = st.session_state.matcher.query(q_pattern, k=15)
        except Exception as e:
            st.warning(f"æ¨¡å¼åŒ¹é…è°ƒç”¨å‡ºé”™ï¼š{e}")
            sims_pattern = pd.DataFrame()

        st.markdown("**3ï¸âƒ£ æ¨¡å¼åŒ¹é…å‚è€ƒï¼ˆä»…æŒ‰6ä¸ªæ¨¡å¼åŒ¹é…å…¨åº“ï¼‰**")
        if not sims_pattern.empty:
            sims_pattern = sims_pattern.copy()
            if "å¼ºå‚è€ƒ" in sims_pattern.columns:
                sims_pattern["å¼ºå‚è€ƒæ ‡è®°"] = sims_pattern["å¼ºå‚è€ƒ"].map(
                    lambda x: "â­ å¼ºå‚è€ƒ" if bool(x) else ""
                )
            if "_distance" in sims_pattern.columns:
                sims_pattern = sims_pattern.drop(columns=["_distance"])
            st.dataframe(sims_pattern, use_container_width=True)
        else:
            st.info("æš‚æ— æ¨¡å¼åŒ¹é…ç»“æœï¼ˆå¯èƒ½æ˜¯æ¨¡å¼æˆ–å†å²åº“é…ç½®æœ‰é—®é¢˜ï¼‰ã€‚")

        # 4) ç³»ç»Ÿæ¨èç»“æœï¼ˆä¸»é€‰ + å¤‡é€‰ï¼Œé˜ˆå€¼=0.03ï¼‰
        try:
            rec = system_recommendation_for_match(
                i=i,
                df_pro=df_pro,
                df_ens=df_ens,
                sims_basic=sims_basic,
                sims_pattern=sims_pattern,
                outcome_col=OUTCOME_COL,
                threshold=0.03,  # ä½ è¯„ä¼°åé€‰å®šçš„é˜ˆå€¼
            )
            main_pick = rec["ä¸»é€‰"]
            backup_pick = rec["å¤‡é€‰"]
            scores = rec["total_score"]

            st.markdown("**4ï¸âƒ£ ç³»ç»Ÿæ¨èç»“æœï¼ˆç»¼åˆæ¨¡å‹ + å†å² + æ¨¡å¼ï¼‰**")
            if backup_pick:
                st.write(f"ç³»ç»Ÿæ¨èä¸»é€‰ï¼š**{main_pick}** ï¼Œå¤‡é€‰ï¼š**{backup_pick}**")
            else:
                st.write(f"ç³»ç»Ÿæ¨èä¸»é€‰ï¼š**{main_pick}**ï¼ˆæš‚ä¸ç»™å‡ºå¤‡é€‰ï¼‰")

            score_str = " | ".join([f"{o}: {scores[o]:.3f}" for o in outcomes])
            st.caption(f"æ€»åˆ†ç»†èŠ‚ï¼š{score_str}")
        except Exception as e:
            st.info(f"ç³»ç»Ÿæ¨èè®¡ç®—å‡ºé”™ï¼ˆå¯æš‚æ—¶å¿½ç•¥ï¼‰ï¼š{e}")

    # 5) å·®å€¼æ¨¡å¼å¯¼å‡º
    if st.session_state.pattern_records:
        df_patterns = pd.DataFrame(st.session_state.pattern_records).sort_values("æ¯”èµ›ç¼–å·")
        st.subheader("ğŸ“¤ å·®å€¼æ¨¡å¼å¯¼å‡ºï¼ˆæ¯åœºæ–°æ¯”èµ›çš„ PRO / PROèåˆ å·®å€¼æ¨¡å¼ï¼‰")
        st.dataframe(df_patterns, use_container_width=True)
        st.download_button(
            "â¬‡ï¸ ä¸‹è½½å·®å€¼æ¨¡å¼ï¼ˆCSVï¼‰",
            df_patterns.to_csv(index=False).encode("utf-8-sig"),
            "gap_patterns_export_new_matches.csv",
            "text/csv",
        )

# ---------- é¢„æµ‹ ----------
if not st.session_state.input_df.empty and st.button("ğŸ¯ è¿è¡Œé¢„æµ‹"):
    df_odds  = st.session_state.input_df.copy()
    X_feat   = add_extra_features(df_odds)
    X_imp    = X_feat.values.astype(float)
    for j in range(0, 15, 3):
        inv = 1 / X_imp[:, j:j+3]
        X_imp[:, j:j+3] = inv / inv.sum(axis=1, keepdims=True)

    p_draw = 0.6*draw_hgb.predict_proba(X_imp)[:,1] + 0.4*draw_tree.predict_proba(X_imp)[:,1]
    p_draw = np.clip(p_draw + 0.10*np.power(1-p_draw,0.50), 0, 1)

    p_wl   = winlose_hgb.predict_proba(X_imp)
    p_base = np.zeros((len(X_imp),3))
    p_base[:,1] = p_draw
    p_base[:,0] = p_wl[:,1]*(1-p_draw)
    p_base[:,2] = p_wl[:,0]*(1-p_draw)

    df_pro  = predict_model_pro(df_odds)
    prob2   = [c for c in df_pro.columns if c.startswith("P(")]
    for pc in prob2: df_pro[pc].fillna(0, inplace=True)
    ens_in  = pd.concat([df_odds.reset_index(drop=True),
                         df_pro[["average_gap"]+prob2].reset_index(drop=True)], axis=1)
    try:
        df_ens = predict_model_pro_ensemble(ens_in)
        p_ens  = df_ens[[f"P({o})" for o in outcomes]].values
    except:
        p_ens = np.zeros_like(p_base)

    try:
        df_meta = predict_model_meta(df_odds)
        p_meta  = df_meta[[f"P({o})" for o in outcomes]].values
    except:
        p_meta = np.zeros_like(p_base)

    p_multi = multi_clf.predict_proba(X_imp)

    w_base, w_ens, w_meta, w_multi = 0.10, 0.70, 0.10, 0.00
    wsum   = w_base + w_ens + w_meta + w_multi

    p_final = (w_base  * p_base  +
               w_ens   * p_ens   +
               w_meta  * p_meta  +
               w_multi * p_multi) / wsum

    p_final /= p_final.sum(axis=1, keepdims=True)

    preds = [outcomes[k] for k in p_final.argmax(axis=1)]
    df_res = pd.DataFrame(p_final*100, columns=[f"{o}(%)" for o in outcomes])
    df_res.insert(0,"æœ€ç»ˆé¢„æµ‹", preds)
    df_res.index = np.arange(1,len(df_res)+1); df_res.index.name="æ¯”èµ›ç¼–å·"

    st.subheader("ğŸ“Š ç»¼åˆæ¨¡å‹é¢„æµ‹ç»“æœ")
    st.dataframe(df_res, use_container_width=True)
    st.download_button(
        "â¬‡ï¸ ä¸‹è½½ç»“æœ",
        df_res.to_csv(index=True).encode("utf-8-sig"),
        "predictions.csv",
        "text/csv"
    )
