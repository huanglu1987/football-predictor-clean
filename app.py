# app.py
# ------------------------------------------------------------------
# Football Match Predictor â€” GitHub éƒ¨ç½²ç‰ˆ
#  â€¢ ç›¸å¯¹è·¯å¾„ç®¡ç†æ•°æ®
#  â€¢ æ”¯æŒå¤šåœºé¢„æµ‹ã€å†å²ç›¸ä¼¼å›æŸ¥
# ------------------------------------------------------------------
import os
import streamlit as st
import pandas as pd
import numpy as np

from models.pro_model import predict_model_pro
from models.model_pro_ensemble import predict_model_pro_ensemble
from similarity_matcher import SimilarityMatcher

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ é¡µé¢é…ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="Football Match Predictor", layout="wide")
st.title("âš½ Football Match Predictor")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¸¸é‡å®šä¹‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
company_order = ["Bet365", "ç«‹åš", "Interwetten", "Pinnacle", "William Hill"]
outcomes      = ["ä¸»èƒœ", "å¹³å±€", "å®¢èƒœ"]
feature_cols  = [f"{cmp}_{oc}" for cmp in company_order for oc in outcomes]

# é»˜è®¤å†å²æ•°æ®è·¯å¾„ï¼šä»“åº“æ ¹ç›®å½•ä¸‹ data/ å­ç›®å½•
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
HIST_PATH = os.path.join(BASE_DIR, "data", "prediction_results (43).xlsx")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Session State åˆå§‹åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "uploaded_df" not in st.session_state:
    st.session_state.uploaded_df = pd.DataFrame(columns=feature_cols)
if "current_odds" not in st.session_state:
    st.session_state.current_odds = []
if "input_odds_line" not in st.session_state:
    st.session_state.input_odds_line = ""
if "matcher" not in st.session_state:
    # ä¼ å…¥ None ä½¿ç”¨ similarity_matcher.py é»˜è®¤ path
    st.session_state.matcher = SimilarityMatcher()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¾…åŠ©å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def handle_input_odds():
    """è¯»å–ä¸€è¡Œâ€œä¸»èƒœ å¹³å±€ å®¢èƒœâ€æ‰“æ•£ä¸ºæµ®ç‚¹åˆ—è¡¨"""
    line = st.session_state.input_odds_line.strip()
    parts = line.split()
    if len(parts) == 3:
        try:
            odds = list(map(float, parts))
            if len(st.session_state.current_odds) < 5:
                st.session_state.current_odds.append(odds)
                idx = len(st.session_state.current_odds) - 1
                st.success(f"âœ… å·²æ·»åŠ ï¼š{company_order[idx]}")
            else:
                st.warning("å·²å½•å…¥ 5 å®¶å…¬å¸èµ”ç‡ï¼Œå¦‚éœ€ä¿®æ”¹è¯·æ’¤å›ã€‚")
        except ValueError:
            st.error("âŒ èµ”ç‡å¿…é¡»ä¸ºæ•°å­—")
    elif line:
        st.error("âŒ æ ¼å¼åº”ä¸ºï¼šä¸»èƒœ å¹³å±€ å®¢èƒœ")
    st.session_state.input_odds_line = ""


def compute_upset_score(row):
    """è®¡ç®—å†·é—¨åŸå§‹åˆ† = max(avg) - min(avg)"""
    avg_home = np.mean([row[f"{c}_ä¸»èƒœ"] for c in company_order])
    avg_draw = np.mean([row[f"{c}_å¹³å±€"] for c in company_order])
    avg_away = np.mean([row[f"{c}_å®¢èƒœ"] for c in company_order])
    return float(max(avg_home, avg_draw, avg_away) - min(avg_home, avg_draw, avg_away))


def generate_recommendation_score(row):
    """è®¡ç®—èåˆä¿¡å¿ƒ & æ ‡è®°æ¨¡å‹ä¸€è‡´"""
    row["èåˆä¿¡å¿ƒ"] = round(0.6 * row["PROèåˆæ¨¡å‹_gap"] + 0.4 * row["PRO_gap"], 4)
    row["æ¨¡å‹ä¸€è‡´"] = (row["PRO_æœ€ç»ˆé¢„æµ‹ç»“æœ"] == row["PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ"])
    return row


def classify_recommendation(sc):
    """æ ¹æ®é˜ˆå€¼è¿”å›æ¨èç­‰çº§"""
    if sc >= 0.80:
        return "â­â­â­â­ å¼ºçƒˆæ¨è"
    elif sc >= 0.60:
        return "â­â­â­ å¯åšä¸€è¯•"
    elif sc >= 0.40:
        return "â­â­ æ½œåŠ›åœºæ¬¡"
    elif sc >= 0.20:
        return "â­ ä¸€èˆ¬åœºæ¬¡"
    else:
        return "âŒ ä¸å»ºè®®æŠ•æ³¨"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç”¨æˆ·è¾“å…¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mode = st.radio(
    "è¯·é€‰æ‹©æ¯”èµ›æ•°æ®è¾“å…¥æ–¹å¼",
    ["ğŸ“ ä¸Šä¼ Excel", "ğŸ–Šï¸ æ‰‹åŠ¨å½•å…¥ï¼ˆé€å…¬å¸ä¸€è¡Œï¼‰"]
)

if mode == "ğŸ“ ä¸Šä¼ Excel":
    file = st.file_uploader("ä¸Šä¼ åŒ…å« 15 åˆ—èµ”ç‡çš„ Excel æ–‡ä»¶", type=["xlsx"])
    if file:
        df_upload = pd.read_excel(file)
        df_upload = df_upload[feature_cols]
        st.session_state.uploaded_df = df_upload
        st.success(f"âœ… å·²è¯»å– {len(df_upload)} åœºæ¯”èµ›")
        st.dataframe(df_upload)
else:
    st.markdown(f"ğŸ¯ å½•å…¥é¡ºåºï¼š**{' â†’ '.join(company_order)}**")
    st.text_input(
        "âœï¸ ç²˜è´´èµ”ç‡ï¼ˆä¸»èƒœ å¹³å±€ å®¢èƒœï¼‰",
        key="input_odds_line",
        on_change=handle_input_odds
    )
    # å±•ç¤ºæ‰‹åŠ¨å½•å…¥è¿›åº¦
    if st.session_state.current_odds:
        tmp = pd.DataFrame(
            st.session_state.current_odds,
            columns=outcomes,
            index=company_order[:len(st.session_state.current_odds)]
        )
        st.table(tmp)
        if st.button("ğŸ”™ æ’¤å›ä¸Šä¸€å®¶å…¬å¸"):
            st.session_state.current_odds.pop()
            st.warning("å·²æ’¤å›ä¸Šä¸€å®¶å…¬å¸èµ”ç‡")
    # æ”¶é›†æ»¡ 5 è¡Œåè¿½åŠ  DataFrame
    if len(st.session_state.current_odds) == 5:
        row = {
            f"{company_order[i]}_{oc}": val
            for i, odds in enumerate(st.session_state.current_odds)
            for oc, val in zip(outcomes, odds)
        }
        df_manual = pd.DataFrame([row], columns=feature_cols)
        st.session_state.uploaded_df = pd.concat([
            st.session_state.uploaded_df, df_manual
        ], ignore_index=True)
        st.session_state.current_odds = []
        st.success("ğŸ‰ å·²æ·»åŠ  1 åœºæ¯”èµ›æ•°æ®")
        st.dataframe(st.session_state.uploaded_df)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ é¢„æµ‹ä¸å±•ç¤º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.button("ğŸ§  åŒæ—¶è¿è¡Œ PRO + èåˆæ¨¡å‹é¢„æµ‹"):
    df_in = st.session_state.uploaded_df
    if df_in.empty:
        st.error("âŒ è¯·å…ˆä¸Šä¼ æˆ–å½•å…¥æ¯”èµ›æ•°æ®ã€‚")
    else:
        # å¡«å……ç¼ºå¤±å€¼å‡å€¼
        df_filled = df_in.copy()
        df_filled[feature_cols] = df_filled[feature_cols].fillna(df_filled[feature_cols].mean())
        
        # PRO æ¨¡å‹é¢„æµ‹
        df_pro = predict_model_pro(df_filled)
        pro_preds = df_pro["æœ€ç»ˆé¢„æµ‹ç»“æœ"].values
        pro_gaps  = df_pro["average_gap"].values

        # èåˆæ¨¡å‹é¢„æµ‹
        df_ens = predict_model_pro_ensemble(df_filled)
        fusion_preds = df_ens["PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ"].values
        fusion_gaps  = df_ens["PROèåˆæ¨¡å‹_gap"].values

        # æ¦‚ç‡åˆ—
        prob_cols = [f"P({oc})" for oc in outcomes]
        if set(prob_cols).issubset(df_ens.columns):
            probs = df_ens[prob_cols].values
        else:
            probs = np.zeros((len(df_filled), 3))

        # æ„é€ ç»“æœ DataFrame
        result_df = df_filled.copy().reset_index(drop=True)
        result_df["æ¯”èµ›åºå·"]               = np.arange(1, len(df_filled)+1)
        result_df["PRO_æœ€ç»ˆé¢„æµ‹ç»“æœ"]      = pro_preds
        result_df["PRO_gap"]               = pro_gaps
        result_df["PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ"]    = fusion_preds
        result_df["PROèåˆæ¨¡å‹_gap"]       = fusion_gaps
        result_df["P(ä¸»èƒœ)"]               = probs[:,0]
        result_df["P(å¹³å±€)"]               = probs[:,1]
        result_df["P(å®¢èƒœ)"]               = probs[:,2]

        # è®¡ç®—èåˆä¿¡å¿ƒä¸æ¨¡å‹ä¸€è‡´
        result_df = result_df.apply(generate_recommendation_score, axis=1)
        # è®¡ç®—å†·é—¨åˆ†ä¸æ ‡å‡†åŒ–
        result_df["å†·é—¨åŸå§‹åˆ†"]     = result_df.apply(compute_upset_score, axis=1)
        result_df["å†·é—¨æ ‡å‡†åŒ–å¾—åˆ†"] = ((result_df["å†·é—¨åŸå§‹åˆ†"]-2.16)/1.47).round(2)
        # æ¨èæ€»åˆ†ä¸ç­‰çº§
        result_df["æ¨èæ€»åˆ†"] = (0.7*result_df["èåˆä¿¡å¿ƒ"] - 0.3*result_df["å†·é—¨æ ‡å‡†åŒ–å¾—åˆ†"]).round(2)
        result_df["æ¨èç­‰çº§"] = result_df["æ¨èæ€»åˆ†"].apply(classify_recommendation)

        # ä¸»è¡¨å±•ç¤º
        st.subheader("ğŸ“Š æ¨¡å‹é¢„æµ‹ç»“æœ")
        display = result_df[[
            "æ¯”èµ›åºå·",
            "PRO_æœ€ç»ˆé¢„æµ‹ç»“æœ","PRO_gap",
            "PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ","PROèåˆæ¨¡å‹_gap",
            "èåˆä¿¡å¿ƒ","å†·é—¨æ ‡å‡†åŒ–å¾—åˆ†",
            "æ¨èæ€»åˆ†"
        ]]
        st.dataframe(
            display.style.format({
                "PRO_gap":"{:.4f}",
                "PROèåˆæ¨¡å‹_gap":"{:.4f}",
                "èåˆä¿¡å¿ƒ":"{:.4f}",
                "å†·é—¨æ ‡å‡†åŒ–å¾—åˆ†":"{:.2f}",
                "æ¨èæ€»åˆ†":"{:.2f}"
            })
        )

        # ç›¸ä¼¼å†å²æ¯”èµ› Top-5
        st.markdown("## ğŸ” ç›¸ä¼¼å†å²æ¯”èµ›ï¼ˆTop-5ï¼‰")
        matcher = st.session_state.matcher
        for _, row in result_df.iterrows():
            query = {
                "PRO_gap": row["PRO_gap"],
                "PROèåˆæ¨¡å‹_gap": row["PROèåˆæ¨¡å‹_gap"],
                "èåˆä¿¡å¿ƒ": row["èåˆä¿¡å¿ƒ"],
                "æ¨èæ€»åˆ†": row["æ¨èæ€»åˆ†"],
                "pair": f"{row['PRO_æœ€ç»ˆé¢„æµ‹ç»“æœ']}-{row['PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ']}"
            }
            top5 = matcher.query(query, k=5)
            with st.expander(f"æ¯”èµ› {int(row['æ¯”èµ›åºå·'])} â†’ é¢„æµ‹ {row['PRO_æœ€ç»ˆé¢„æµ‹ç»“æœ']}"):
                st.dataframe(
                    top5[[
                        "æ¯”èµ›åºå·","æ¯”èµ›ç»“æœ",
                        "PRO_æœ€ç»ˆé¢„æµ‹ç»“æœ","PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ",
                        "PRO_gap","PROèåˆæ¨¡å‹_gap",
                        "èåˆä¿¡å¿ƒ","æ¨èæ€»åˆ†","_distance"
                    ]].style.format({
                        "PRO_gap":"{:.4f}",
                        "PROèåˆæ¨¡å‹_gap":"{:.4f}",
                        "èåˆä¿¡å¿ƒ":"{:.4f}",
                        "æ¨èæ€»åˆ†":"{:.2f}",
                        "_distance":"{:.2f}"
                    })
                )
