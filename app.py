# app.py  â€“  å†å²ç›¸ä¼¼æ¯”èµ› Top5 æŸ¥çœ‹ä¸å¯¼å‡º + å†å² TOP5 çš„ 6 ä¸ªå·®å€¼æ¨¡å¼å±•ç¤º
#
# æ˜¾ç¤ºå†…å®¹ï¼š
#   - æ¯åœºå½“å‰æ¯”èµ›ï¼š
#       * å†å²ç›¸ä¼¼ Top5ï¼ˆä¸¥æ ¼æŒ‰ SimilarityMatcher.query æ’åºï¼‰
#       * Top5 çš„ 6 ä¸ªå·®å€¼æ¨¡å¼ï¼š
#           - PRO_gapï¼š0-1-2, 1-2-3, 2-3-4
#           - PROèåˆæ¨¡å‹_gapï¼š0-1-2, 1-2-3, 2-3-4
#
# Top5 è¡¨åªæ˜¾ç¤ºåˆ—ï¼š
#   - æ¯”èµ›åºå·ï¼ˆæ¥è‡ªâ€œæ¯”èµ›åºå·â€æˆ–â€œæ¯”èµ›ç¼–å·â€ï¼‰
#   - æ¯”èµ›ç»“æœï¼ˆè‡ªåŠ¨è¯†åˆ«ï¼šæ¯”èµ›ç»“æœ / æ¯”èµ›ç»“æœ_y / æ¯”èµ›ç»“æœ_xï¼‰
#   - PRO_æœ€ç»ˆé¢„æµ‹ç»“æœ
#   - PRO_gapï¼ˆ4 ä½å°æ•°ï¼‰
#   - PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ
#   - PROèåˆæ¨¡å‹_gapï¼ˆ4 ä½å°æ•°ï¼‰
#
# å¯¼å‡ºå†…å®¹ï¼š
#   - å½“å‰æ¯”èµ›åºå·ã€å½“å‰ä¸»é˜Ÿ/å®¢é˜Ÿ
#   - å†å²ä¸»é˜Ÿ/å®¢é˜Ÿ
#   - å†å²æ¯”èµ›åºå·ã€å†å²æ¯”èµ›ç»“æœã€å†å²PRO_æœ€ç»ˆé¢„æµ‹ç»“æœã€å†å²PRO_gapã€å†å²PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœã€å†å²PROèåˆæ¨¡å‹_gapï¼ˆ4 ä½å°æ•°ï¼‰
#   - åœ¨ä¸åŒâ€œå½“å‰æ¯”èµ›åºå·â€çš„ Top5 ä¹‹é—´æ’å…¥ä¸€è¡Œç©ºç™½è¡Œï¼Œæ–¹ä¾¿åˆ†ç»„æŸ¥çœ‹

import math
from pathlib import Path
from typing import Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st

from models.pro_model import predict_model_pro
from models.model_pro_ensemble import predict_model_pro_ensemble
from models.predict_model_meta import predict_model_meta
from similarity_matcher import SimilarityMatcher

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ UI è®¾ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="å†å²ç›¸ä¼¼æ¯”èµ› Top5 å¯¼å‡º", layout="wide")

st.markdown("""
<style>
.stApp { background:linear-gradient(135deg,#f0f8ff,#e6e6fa); }
.company-name{font-size:1.05em;font-weight:600;text-shadow:1px 1px 2px rgba(0,0,0,0.2);}
.stTextInput>div>div>input{max-width:260px;}
.stButton>button{margin-top:4px;margin-bottom:8px;}

/* ç´§å‡‘å†å²è¡¨æ ¼æ ·å¼ */
.hist-table{
  table-layout: fixed;
  width: 100%;
  border-collapse: collapse;
}
.hist-table th, .hist-table td{
  max-width: 80px;
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
  padding: 3px 4px;
  border-bottom: 1px solid #ddd;
  font-size: 0.85rem;
}
.hist-table th{
  font-weight: 600;
  background-color:#f5f5ff;
}

/* å·®å€¼æ¨¡å¼çš„å°è¡¨æ ¼ */
.pattern-table{
  border-collapse: collapse;
  margin-top: 4px;
}
.pattern-table th, .pattern-table td{
  border: 1px solid #ddd;
  padding: 3px 6px;
  font-size: 0.85rem;
}
.pattern-table th{
  background-color:#eef2ff;
  font-weight: 600;
}
</style>
""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ åŸºæœ¬å¸¸é‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR  = Path(__file__).parent
DATA_FILE = BASE_DIR / "data" / "new_matches.xlsx"
HIST_PATH = BASE_DIR / "data" / "prediction_results (43).xlsx"

companies = ["Bet365","ç«‹åš","Interwetten","Pinnacle","William Hill"]
TEAM_COLS = ["ä¸»é˜Ÿ", "å®¢é˜Ÿ"]
outcomes  = ["ä¸»èƒœ","å¹³å±€","å®¢èƒœ"]
ODDS_COLS = [f"{c}_{o}" for c in companies for o in outcomes]
OUTCOME_COL = "æ¯”èµ›ç»“æœ"

# ---------- æ¸²æŸ“ç´§å‡‘è¡¨æ ¼ ----------
def render_compact_table(df: pd.DataFrame):
    """ç”¨å›ºå®šåˆ—å®½çš„ HTML è¡¨æ ¼ç´§å‡‘æ˜¾ç¤º DataFrameï¼Œå¹¶ç»Ÿä¸€æ•°å€¼ä¸º 4 ä½å°æ•°ã€‚"""
    if df is None or df.empty:
        st.info("æš‚æ— æ•°æ®ã€‚")
        return
    html = df.to_html(
        index=False,
        classes="hist-table",
        border=0,
        escape=False,
        float_format=lambda x: f"{x:.4f}",
    )
    st.markdown(html, unsafe_allow_html=True)

# ---------- è¯†åˆ«â€œæ¯”èµ›ç»“æœâ€åˆ—å ----------
def get_result_value(row: pd.Series) -> str:
    """ä»ä¸€è¡Œä¸­å–æ¯”èµ›ç»“æœï¼šä¼˜å…ˆæ¯”èµ›ç»“æœï¼Œå…¶æ¬¡æ¯”èµ›ç»“æœ_yï¼Œå†å…¶æ¬¡æ¯”èµ›ç»“æœ_xã€‚"""
    for col in ["æ¯”èµ›ç»“æœ", "æ¯”èµ›ç»“æœ_y", "æ¯”èµ›ç»“æœ_x"]:
        if col in row and pd.notna(row[col]) and str(row[col]) != "":
            return str(row[col])
    return ""

# ---------- å·®å€¼æ¨¡å¼å·¥å…· ----------
def _truncate_two_decimals(x: float) -> float:
    try:
        x = float(x)
    except (TypeError, ValueError):
        return 0.0
    if x >= 0:
        return math.floor(x * 100 + 1e-8) / 100.0
    else:
        return math.ceil(x * 100 - 1e-8) / 100.0


def format_gap_pattern(values) -> str:
    """
    ä¼ å…¥é•¿åº¦ä¸º 3 çš„ gap åˆ—è¡¨ï¼Œè¿”å›å½¢å¦‚ '(outer)d1-d2' çš„å­—ç¬¦ä¸²ã€‚
    """
    if len(values) != 3:
        return ""
    vs = sorted(_truncate_two_decimals(v) for v in values)
    d1 = int(math.floor(abs(vs[1] - vs[0]) * 100 + 1e-8))
    d2 = int(math.floor(abs(vs[2] - vs[1]) * 100 + 1e-8))
    if (d1 == 0 and d2 != 0) or (d2 == 0 and d1 != 0):
        first, second = 0, d2 if d1 == 0 else d1
    else:
        first, second = d1, d2
    outer = abs(first - second)
    return f"({outer}){first}-{second}"


def compute_gap_patterns(sims: pd.DataFrame, col: str) -> dict:
    """
    ä»å†å²ç›¸ä¼¼æ¯”èµ›ç»“æœ sims ä¸­ï¼Œä¸ºæŒ‡å®š gap åˆ—ï¼ˆå¦‚ 'PRO_gap' æˆ– 'PROèåˆæ¨¡å‹_gap'ï¼‰
    è®¡ç®— 0-1-2, 1-2-3, 2-3-4 ä¸‰ä¸ªçª—å£çš„å·®å€¼æ¨¡å¼ã€‚
    è¿”å›ç¤ºä¾‹ï¼š
        {'0-1-2': '(3)7-4', '1-2-3': '(5)2-7', '2-3-4': '(1)6-5'}
    """
    if col not in sims.columns:
        return {}
    vals = sims[col].tolist()
    windows = [("0-1-2", 0), ("1-2-3", 1), ("2-3-4", 2)]
    patterns = {}
    for label, start in windows:
        if len(vals) >= start + 3:
            triple = vals[start:start + 3]
            patterns[label] = format_gap_pattern(triple)
    return patterns

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. è¡ç”Ÿç‰¹å¾ï¼ˆä¾› PRO æ¨¡å‹ç”¨ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€
def add_extra_features(df_odds: pd.DataFrame) -> pd.DataFrame:
    extra = pd.DataFrame(index=df_odds.index)
    mat = df_odds.values.reshape(-1, len(companies), len(outcomes))  # (N,5,3)

    cv_vals    = np.std(mat, axis=1) / np.mean(mat, axis=1)
    range_vals = np.max(mat, axis=1) - np.min(mat, axis=1)
    extra[["cv_home","cv_draw","cv_away"]]           = cv_vals
    extra[["range_home","range_draw","range_away"]] = range_vals

    inv = 1 / mat
    imp = inv / inv.sum(axis=2, keepdims=True)
    p_diff = np.abs(imp[:,:,0].mean(axis=1) - imp[:,:,2].mean(axis=1))
    extra["p_diff"] = p_diff

    return pd.concat([df_odds.reset_index(drop=True),
                      extra.reset_index(drop=True)], axis=1)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. Session åˆå§‹åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("âš½ å†å²ç›¸ä¼¼æ¯”èµ› Top5 æŸ¥çœ‹ä¸å¯¼å‡º")

if "input_df" not in st.session_state:
    st.session_state.input_df = pd.DataFrame(columns=TEAM_COLS + ODDS_COLS)
if "matcher" not in st.session_state:
    if not HIST_PATH.exists():
        st.error(f"æ‰¾ä¸åˆ°å†å²åº“æ–‡ä»¶ï¼š{HIST_PATH}")
    else:
        st.session_state.matcher = SimilarityMatcher(str(HIST_PATH))

# ---------- æ•°æ®è¾“å…¥ ----------
mode = st.radio("ğŸ“¥ æ•°æ®è¾“å…¥æ–¹å¼", ["ä¸Šä¼ æ–‡ä»¶", "æ‰‹åŠ¨å½•å…¥"], horizontal=True)

if mode == "ä¸Šä¼ æ–‡ä»¶":
    up = st.file_uploader("ä¸Šä¼ èµ”ç‡æ–‡ä»¶ (å»ºè®®åŒ…å«ä¸»é˜Ÿ/å®¢é˜Ÿ + 15åˆ—èµ”ç‡)", type=["xlsx", "csv"])
    if up is not None:
        df_up = pd.read_csv(up) if up.name.endswith(".csv") else pd.read_excel(up)
        for col in TEAM_COLS:
            if col not in df_up.columns:
                df_up[col] = ""
        missing_odds = [c for c in ODDS_COLS if c not in df_up.columns]
        if missing_odds:
            st.error(f"ä¸Šä¼ æ–‡ä»¶ç¼ºå°‘ä»¥ä¸‹èµ”ç‡åˆ—ï¼š{missing_odds}")
        else:
            st.session_state.input_df = df_up[TEAM_COLS + ODDS_COLS].copy()
            st.success(f"âœ… å·²è¯»å– {len(df_up)} åœºæ¯”èµ›")
            st.dataframe(st.session_state.input_df)
else:
    st.subheader("ğŸ–Š æ‰‹åŠ¨å½•å…¥ (é€å…¬å¸ä¸€è¡Œ)")
    with st.form("manual", clear_on_submit=True):
        c1, c2 = st.columns(2)
        home_team = c1.text_input("ä¸»é˜Ÿåç§°", key="home_team")
        away_team = c2.text_input("å®¢é˜Ÿåç§°", key="away_team")

        inps = {}
        st.markdown("è¯·è¾“å…¥å„åšå½©å…¬å¸èµ”ç‡ï¼ˆæ ¼å¼ï¼šä¸»èƒœ å¹³å±€ å®¢èƒœï¼Œä¾‹å¦‚ï¼š2.05 3.60 3.50ï¼‰")
        for comp in companies:
            r1, r2 = st.columns([1, 2])
            r1.markdown(f"<div class='company-name'>{comp}</div>", unsafe_allow_html=True)
            inps[comp] = r2.text_input("", placeholder="2.05 3.60 3.50", key=f"man_{comp}")
        if st.form_submit_button("æ·»åŠ æ¯”èµ›"):
            row_odds = []
            ok = True
            for comp in companies:
                parts = inps[comp].split()
                if len(parts) != 3:
                    st.error(f"{comp} éœ€è¾“å…¥ 3 ä¸ªèµ”ç‡"); ok = False; break
                try:
                    row_odds += [float(x) for x in parts]
                except ValueError:
                    st.error(f"{comp} çš„èµ”ç‡å¿…é¡»æ˜¯æ•°å­—"); ok = False; break
            if ok:
                new_row = pd.DataFrame([[home_team, away_team] + row_odds],
                                       columns=TEAM_COLS + ODDS_COLS)
                st.session_state.input_df = pd.concat(
                    [st.session_state.input_df, new_row],
                    ignore_index=True
                )
                st.success("âœ… å·²æ·»åŠ 1åœºæ¯”èµ›")
                st.dataframe(st.session_state.input_df)

# ---------- å†å²ç›¸ä¼¼ Top5 æ˜¾ç¤º + å·®å€¼æ¨¡å¼ + å¯¼å‡º ----------
if not st.session_state.input_df.empty and "matcher" in st.session_state:
    st.subheader("ğŸ” å†å²ç›¸ä¼¼æ¯”èµ› Top5ï¼ˆæŒ‰ SimilarityMatcher åŸå§‹é¡ºåºï¼‰")

    df_odds = st.session_state.input_df[ODDS_COLS].copy()

    # å½“å‰æ¯”èµ› PRO æ¨¡å‹é¢„æµ‹ï¼ˆç”¨äº q_basicï¼‰
    df_pro = predict_model_pro(df_odds)
    prob_cols = [c for c in df_pro.columns if c.startswith("P(")]
    for pc in prob_cols:
        df_pro[pc].fillna(0, inplace=True)

    # PRO èåˆè¾“å‡º
    ens_in = pd.concat([
        df_odds.reset_index(drop=True),
        df_pro[["average_gap"] + prob_cols].reset_index(drop=True)
    ], axis=1)
    try:
        df_ens = predict_model_pro_ensemble(ens_in)
    except Exception:
        df_ens = pd.DataFrame({
            "PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ": ["å¹³å±€"] * len(df_pro),
            "PROèåˆæ¨¡å‹_gap": [0.0] * len(df_pro)
        })

    # METAï¼ˆç”¨äº q_basicï¼Œå»¶ç»­æ—§é€»è¾‘ï¼‰
    try:
        df_meta = predict_model_meta(df_odds)
    except Exception:
        df_meta = pd.DataFrame()

    matcher: SimilarityMatcher = st.session_state.matcher

    export_rows = []

    for i in range(len(st.session_state.input_df)):
        home = st.session_state.input_df.loc[i, "ä¸»é˜Ÿ"] if "ä¸»é˜Ÿ" in st.session_state.input_df.columns else ""
        away = st.session_state.input_df.loc[i, "å®¢é˜Ÿ"] if "å®¢é˜Ÿ" in st.session_state.input_df.columns else ""

        title_str = f"ç¬¬ {i+1} åœº"
        if home or away:
            title_str += f"ï¼š{home} vs {away}"
        st.markdown(f"### â–¶ {title_str}")

        # æ„é€  q_basic
        curr_pro_res = df_pro.loc[i, "æœ€ç»ˆé¢„æµ‹ç»“æœ"] if "æœ€ç»ˆé¢„æµ‹ç»“æœ" in df_pro.columns else ""
        curr_ens_res = df_ens.loc[i, "PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ"] if "PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ" in df_ens.columns else ""
        curr_pair = f"{curr_pro_res}-{curr_ens_res}" if curr_pro_res and curr_ens_res else ""

        q_basic = {
            "PRO_gap": df_pro.loc[i, "average_gap"],
            "PROèåˆæ¨¡å‹_gap": df_ens.loc[i, "PROèåˆæ¨¡å‹_gap"],
            "èåˆä¿¡å¿ƒ": df_meta.loc[i, "èåˆä¿¡å¿ƒ"] if "èåˆä¿¡å¿ƒ" in df_meta.columns else 0,
            "æ¨èæ€»åˆ†": df_meta.loc[i, "æ¨èæ€»åˆ†"] if "æ¨èæ€»åˆ†" in df_meta.columns else 0,
            "pair": curr_pair
        }

        # ä¸¥æ ¼ä½¿ç”¨ SimilarityMatcher è¿”å›é¡ºåºï¼šTop5
        try:
            sims_basic_full = matcher.query(q_basic, k=5)
        except Exception as e:
            st.warning(f"å†å²åŒ¹é…è°ƒç”¨å‡ºé”™ï¼š{e}")
            sims_basic_full = pd.DataFrame()

        sims_basic_full = sims_basic_full.reset_index(drop=True)

        if sims_basic_full.empty:
            st.info("æœªæ‰¾åˆ°å†å²ç›¸ä¼¼æ¯”èµ›ã€‚")
            continue

        # è®¡ç®— Top5 çš„ PRO / PROèåˆ å·®å€¼æ¨¡å¼
        pro_patterns = compute_gap_patterns(sims_basic_full, "PRO_gap")
        ens_patterns = compute_gap_patterns(sims_basic_full, "PROèåˆæ¨¡å‹_gap")

        pro0 = pro_patterns.get("0-1-2", "")
        pro1 = pro_patterns.get("1-2-3", "")
        pro2 = pro_patterns.get("2-3-4", "")

        ens0 = ens_patterns.get("0-1-2", "")
        ens1 = ens_patterns.get("1-2-3", "")
        ens2 = ens_patterns.get("2-3-4", "")

        # æ„é€ ç”¨äºæ˜¾ç¤ºçš„ DataFrame
        sims_show = sims_basic_full.copy()

        # æ¯”èµ›åºå·ï¼šå†å²åº“ä¸­é€šå¸¸æ˜¯â€œæ¯”èµ›ç¼–å·â€
        if "æ¯”èµ›åºå·" not in sims_show.columns:
            if "æ¯”èµ›ç¼–å·" in sims_show.columns:
                sims_show["æ¯”èµ›åºå·"] = sims_show["æ¯”èµ›ç¼–å·"]
            else:
                sims_show["æ¯”èµ›åºå·"] = ""

        # æ¯”èµ›ç»“æœï¼šè‡ªåŠ¨ä» æ¯”èµ›ç»“æœ / æ¯”èµ›ç»“æœ_y / æ¯”èµ›ç»“æœ_x ä¸­å–
        if "æ¯”èµ›ç»“æœ" not in sims_show.columns:
            if "æ¯”èµ›ç»“æœ_y" in sims_show.columns:
                sims_show["æ¯”èµ›ç»“æœ"] = sims_show["æ¯”èµ›ç»“æœ_y"]
            elif "æ¯”èµ›ç»“æœ_x" in sims_show.columns:
                sims_show["æ¯”èµ›ç»“æœ"] = sims_show["æ¯”èµ›ç»“æœ_x"]
            else:
                sims_show["æ¯”èµ›ç»“æœ"] = ""

        for col in ["PRO_æœ€ç»ˆé¢„æµ‹ç»“æœ", "PRO_gap", "PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ", "PROèåˆæ¨¡å‹_gap"]:
            if col not in sims_show.columns:
                sims_show[col] = ""

        sims_show = sims_show[["æ¯”èµ›åºå·", "æ¯”èµ›ç»“æœ", "PRO_æœ€ç»ˆé¢„æµ‹ç»“æœ", "PRO_gap",
                               "PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ", "PROèåˆæ¨¡å‹_gap"]]

        # æ•°å€¼åˆ—ä¿ç•™ 4 ä½å°æ•°ï¼ˆæ˜¾ç¤ºï¼‰
        for col in ["PRO_gap", "PROèåˆæ¨¡å‹_gap"]:
            if col in sims_show.columns:
                sims_show[col] = pd.to_numeric(sims_show[col], errors="coerce").round(4)

        # æ˜¾ç¤º Top5 å†å²ç›¸ä¼¼æ¯”èµ›
        render_compact_table(sims_show)

        # æ˜¾ç¤ºå†å² Top5 çš„ 6 ä¸ªå·®å€¼æ¨¡å¼
        if pro0 or pro1 or pro2 or ens0 or ens1 or ens2:
            st.markdown("**å·®å€¼æ¨¡å¼ï¼ˆåŸºäºå†å² Top5ï¼‰**")
            pattern_html = f"""
<table class="pattern-table">
  <tr>
    <th></th>
    <th>0-1-2</th>
    <th>1-2-3</th>
    <th>2-3-4</th>
  </tr>
  <tr>
    <th>PRO_gap</th>
    <td>{pro0}</td>
    <td>{pro1}</td>
    <td>{pro2}</td>
  </tr>
  <tr>
    <th>PROèåˆæ¨¡å‹_gap</th>
    <td>{ens0}</td>
    <td>{ens1}</td>
    <td>{ens2}</td>
  </tr>
</table>
"""
            st.markdown(pattern_html, unsafe_allow_html=True)

        # ===== å‡†å¤‡å¯¼å‡ºè¡Œï¼ˆä¿æŒå½“å‰å¾ªç¯çš„ Top5 é¡ºåºï¼‰ =====
        hist_home_col = "ä¸»é˜Ÿ" if "ä¸»é˜Ÿ" in sims_basic_full.columns else None
        hist_away_col = "å®¢é˜Ÿ" if "å®¢é˜Ÿ" in sims_basic_full.columns else None

        for _, row in sims_basic_full.iterrows():
            export_rows.append({
                "å½“å‰æ¯”èµ›åºå·": i + 1,
                "å½“å‰ä¸»é˜Ÿ": home,
                "å½“å‰å®¢é˜Ÿ": away,
                "å†å²æ¯”èµ›åºå·": row["æ¯”èµ›åºå·"] if "æ¯”èµ›åºå·" in row else row.get("æ¯”èµ›ç¼–å·", ""),
                "å†å²æ¯”èµ›ç»“æœ": get_result_value(row),
                "å†å²PRO_æœ€ç»ˆé¢„æµ‹ç»“æœ": row.get("PRO_æœ€ç»ˆé¢„æµ‹ç»“æœ", ""),
                "å†å²PRO_gap": row.get("PRO_gap", ""),
                "å†å²PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ": row.get("PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ", ""),
                "å†å²PROèåˆæ¨¡å‹_gap": row.get("PROèåˆæ¨¡å‹_gap", ""),
                "å†å²ä¸»é˜Ÿ": row.get(hist_home_col, "") if hist_home_col else "",
                "å†å²å®¢é˜Ÿ": row.get(hist_away_col, "") if hist_away_col else "",
            })

    # å¯¼å‡ºå…¨éƒ¨æ¯”èµ›çš„ Top5 å†å²ç›¸ä¼¼åˆ—è¡¨
    if export_rows:
        df_export = pd.DataFrame(export_rows)

        # æ•°å€¼åˆ—ç»Ÿä¸€ä¿ç•™ 4 ä½å°æ•°
        for col in ["å†å²PRO_gap", "å†å²PROèåˆæ¨¡å‹_gap"]:
            if col in df_export.columns:
                df_export[col] = pd.to_numeric(df_export[col], errors="coerce").round(4)

        # ä¸å¯¹ df_export åšæ’åºï¼Œä¿æŒè¿½åŠ é¡ºåºï¼ˆå³ Top5 é¡ºåºï¼‰
        # åœ¨ä¸åŒâ€œå½“å‰æ¯”èµ›åºå·â€ä¹‹é—´æ’å…¥ç©ºç™½è¡Œ
        rows_with_blank = []
        last_match = None
        for _, row in df_export.iterrows():
            match_no = row["å½“å‰æ¯”èµ›åºå·"]
            if last_match is not None and match_no != last_match:
                rows_with_blank.append({col: "" for col in df_export.columns})
            rows_with_blank.append(row.to_dict())
            last_match = match_no

        df_export_with_blank = pd.DataFrame(rows_with_blank, columns=df_export.columns)

        st.subheader("ğŸ“¤ å¯¼å‡ºæ‰€æœ‰æ¯”èµ›çš„å†å²ç›¸ä¼¼ Top5ï¼ˆå«çƒé˜Ÿåç§°ï¼‰")
        render_compact_table(df_export_with_blank.head(30))  # é¢„è§ˆå‰ 30 è¡Œ

        st.download_button(
            "â¬‡ï¸ å¯¼å‡ºå†å²ç›¸ä¼¼ Top5ï¼ˆCSVï¼Œ4ä½å°æ•°+åˆ†ç»„ç©ºè¡Œï¼‰",
            df_export_with_blank.to_csv(index=False).encode("utf-8-sig"),
            "all_matches_top5_history.csv",
            "text/csv",
        )
