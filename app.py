import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.ensemble import HistGradientBoostingClassifier

# å¯¼å…¥ PRO å’Œ META æ¨¡å‹æ¥å£
from models.pro_model import predict_model_pro
from models.model_pro_ensemble import predict_model_pro_ensemble
from models.predict_model_meta import predict_model_meta
from similarity_matcher import SimilarityMatcher

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CSS Styling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<style>
.stApp { background: linear-gradient(135deg, #f0f8ff, #e6e6fa); }
.company-name { font-size:1.1em; font-weight:600; text-shadow:1px 1px 2px rgba(0,0,0,0.2); }
.stTextInput>div>div>input { max-width:200px; }
.stButton>button { margin-top:4px; margin-bottom:8px; }
</style>
""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åŠ è½½è¶³çƒ HGB æ¨¡å‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_soccer_model():
    data_file = Path(__file__).parent / "data" / "new_matches.xlsx"
    df = pd.read_excel(data_file)
    feat_cols = [c for c in df.columns if c not in ["æ¯”èµ›", "æ¯”èµ›ç»“æœ"]]
    X = df[feat_cols].values
    # éšå«æ¦‚ç‡
    X_imp = X.copy()
    for j in range(0, X_imp.shape[1], 3):
        inv = 1 / X_imp[:, j:j+3]
        X_imp[:, j:j+3] = inv / inv.sum(axis=1, keepdims=True)
    y = df["æ¯”èµ›ç»“æœ"].map({"ä¸»èƒœ": 0, "å¹³å±€": 1, "å®¢èƒœ": 2}).values
    # æ‰‹åŠ¨æƒé‡ (ç¤ºä¾‹ç”¨ 1.3ï¼Œè‹¥éœ€è°ƒæ•´å¯ä¿®æ”¹æ­¤å¤„)
    w = np.array([1.0 if yi==0 else 1.3 if yi==1 else 1.0 for yi in y])
    model = HistGradientBoostingClassifier(
        learning_rate=0.01, max_depth=5, loss="log_loss", random_state=42
    )
    model.fit(X_imp, y, sample_weight=w)
    return model, feat_cols

soccer_model, soccer_feats = load_soccer_model()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Streamlit é¡µé¢è®¾ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ç»¼åˆè¶³çƒé¢„æµ‹å™¨", layout="wide")
st.title("âš½ ç»¼åˆè¶³çƒæ¯”èµ›é¢„æµ‹å™¨")

company_order = ["Bet365", "ç«‹åš", "Interwetten", "Pinnacle", "William Hill"]
outcomes      = ["ä¸»èƒœ", "å¹³å±€", "å®¢èƒœ"]
feature_cols  = [f"{c}_{o}" for c in company_order for o in outcomes]

# Session state åˆå§‹åŒ–
if "input_df" not in st.session_state:
    st.session_state.input_df = pd.DataFrame(columns=feature_cols)
if "matcher" not in st.session_state:
    hist_file = Path(__file__).parent / "data" / "prediction_results (43).xlsx"
    st.session_state.matcher = SimilarityMatcher(str(hist_file))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ•°æ®è¾“å…¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mode = st.radio("æ•°æ®è¾“å…¥æ–¹å¼", ["ğŸ“ ä¸Šä¼ æ–‡ä»¶", "ğŸ–Š æ‰‹åŠ¨å½•å…¥"], horizontal=True)
if mode == "ğŸ“ ä¸Šä¼ æ–‡ä»¶":
    uploaded = st.file_uploader("ä¸Šä¼ èµ”ç‡æ–‡ä»¶ (Excel/CSVï¼Œæ¯è¡Œ15åˆ—)", type=["xlsx", "csv"])
    if uploaded:
        df_up = (pd.read_csv(uploaded) if uploaded.name.endswith(".csv")
                 else pd.read_excel(uploaded))
        st.session_state.input_df = df_up[feature_cols]
        st.success(f"âœ… å·²è¯»å– {len(df_up)} åœºæ¯”èµ›æ•°æ®")
        st.dataframe(st.session_state.input_df)
else:
    st.info("è¯·æŒ‰é¡ºåºç²˜è´´å„å…¬å¸èµ”ç‡ï¼šä¸»èƒœ å¹³å±€ å®¢èƒœï¼Œè¾“å…¥å®Œ 5 è¡Œåç‚¹å‡»ã€æäº¤å½•å…¥ã€‘")
    manual = {}
    for comp in company_order:
        manual[comp] = st.text_input(comp, placeholder="2.05 3.60 3.50", key=f"man_{comp}")
    if st.button("æäº¤å½•å…¥"):
        vals = []
        for comp in company_order:
            parts = manual[comp].split()
            vals.extend([float(x) for x in parts])
        st.session_state.input_df.loc[len(st.session_state.input_df)] = vals
        st.success("âœ… å·²æ·»åŠ  1 åœºæ¯”èµ›")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ é¢„æµ‹ä¸èåˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not st.session_state.input_df.empty and st.button("ğŸ”„ è¿è¡Œç»¼åˆé¢„æµ‹"):
    df_in = st.session_state.input_df.copy().fillna(method="ffill")
    n = len(df_in)

    # 1) è¶³çƒ HGB æ¨¡å‹æ¦‚ç‡
    odds = df_in.values.astype(float)
    Xs = odds.copy()
    for j in range(0, 15, 3):
        inv = 1 / odds[:, j:j+3]
        Xs[:, j:j+3] = inv / inv.sum(axis=1, keepdims=True)
    p_soc = soccer_model.predict_proba(Xs)

    # 2) PRO & PRO èåˆ æ¨¡å‹ï¼ˆç¤ºä¾‹ï¼šå¯ä»¥åŒæ—¶æå–å®ƒä»¬çš„æ¦‚ç‡æˆ–å¾—åˆ†ï¼‰
    df_pro = predict_model_pro(df_in)
    df_ens = predict_model_pro_ensemble(df_in)
    # å‡è®¾å®ƒä»¬è¾“å‡ºçš„æ¦‚ç‡åˆ—ä¸º P(ä¸»èƒœ)ã€P(å¹³å±€)ã€P(å®¢èƒœ)
    p_pro = df_pro[[f"P({o})" for o in outcomes]].values if set([f"P({o})" for o in outcomes]).issubset(df_pro.columns) else np.zeros((n,3))
    p_ens = df_ens[[f"P({o})" for o in outcomes]].values if set([f"P({o})" for o in outcomes]).issubset(df_ens.columns) else np.zeros((n,3))

    # 3) META èåˆæ¨¡å‹æ¦‚ç‡ï¼Œå¹¶åš KeyError è‡ªåŠ¨è¡¥é½
    try:
        df_meta = predict_model_meta(df_in)
    except KeyError as e:
        # è‡ªåŠ¨ä»å¼‚å¸¸ä¿¡æ¯ä¸­æå–ç¼ºå¤±åˆ—åå¹¶è¡¥ 0
        import re
        msg = str(e)
        missing = re.findall(r"\\['([^']+)'\\]", msg)
        for col in missing:
            df_in[col] = 0
        df_meta = predict_model_meta(df_in)
    p_meta = df_meta[[f"P({o})" for o in outcomes]].values

    # 4) æœ€ç»ˆå–å¹³å‡èåˆï¼ˆå¯æ ¹æ®ä¸šåŠ¡è°ƒæƒé‡ï¼‰
    p_final = (p_soc + p_pro + p_ens + p_meta) / 4.0
    preds = [outcomes[i] for i in np.argmax(p_final, axis=1)]

    # 5) å±•ç¤ºç»“æœ
    res = pd.DataFrame(p_final * 100, columns=[f"{o}(%)" for o in outcomes])
    res.insert(0, "æœ€ç»ˆé¢„æµ‹", preds)
    res.index = np.arange(1, n+1)
    res.index.name = "æ¯”èµ›ç¼–å·"

    st.subheader("ğŸ“Š ç»¼åˆæ¨¡å‹é¢„æµ‹ç»“æœ")
    st.dataframe(res, use_container_width=True)
    csv = res.to_csv(index=True).encode("utf-8-sig")
    st.download_button("â¬‡ï¸ ä¸‹è½½ç»“æœ CSV", csv, "predictions.csv", "text/csv")
