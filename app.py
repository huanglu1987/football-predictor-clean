# app.py  â€“  å†å²ç›¸ä¼¼æ¯”èµ› Top5 æŸ¥çœ‹ä¸å¯¼å‡º
# + å†å² TOP5 çš„ 6 ä¸ªå·®å€¼æ¨¡å¼
# + æ¨¡å¼è®¡æ•°ä½“ç³»ï¼ˆequal_pro/diff1_pro/...ï¼‰
# + PRO_gap & PROèåˆæ¨¡å‹_gap ç­‰å·®é€’å¢ä¸‰å…ƒç»„æ£€æµ‹
#
# æ˜¾ç¤ºå†…å®¹ï¼ˆæ¯åœºå½“å‰æ¯”èµ›ï¼‰ï¼š
#   1. å†å²ç›¸ä¼¼ Top5ï¼ˆæŒ‰ SimilarityMatcher.query åŸå§‹é¡ºåºï¼‰ï¼š
#       - æ¯”èµ›åºå·
#       - æ¯”èµ›ç»“æœ
#       - PRO_æœ€ç»ˆé¢„æµ‹ç»“æœ
#       - PRO_gapï¼ˆ4 ä½å°æ•°ï¼‰
#       - PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ
#       - PROèåˆæ¨¡å‹_gapï¼ˆ4 ä½å°æ•°ï¼‰
#   2. åŸºäº Top5 è®¡ç®—çš„ 6 ä¸ªå·®å€¼æ¨¡å¼ï¼š
#       - PRO_gapï¼š0-1-2, 1-2-3, 2-3-4
#       - PROèåˆæ¨¡å‹_gapï¼š0-1-2, 1-2-3, 2-3-4
#   3. åŸºäº 6 ä¸ªæ¨¡å¼çš„è®¡æ•°ç»“æœï¼š
#       - equal_pro / diff1_pro
#       - equal_ens / diff1_ens
#       - equal_cross / diff1_cross
#       - total_count / parity(å¥‡å¶)
#   4. PRO_gap & PROèåˆæ¨¡å‹_gap çš„ç­‰å·®é€’å¢ä¸‰å…ƒç»„ï¼š
#       - å…ˆæˆªæ–­ Top5 åˆ°ä¸¤ä½å°æ•°ï¼ˆä¸å››èˆäº”å…¥ï¼‰
#       - å†åˆ¤æ–­æ˜¯å¦å­˜åœ¨ä»»æ„ä¸‰å€¼æ„æˆä¸¥æ ¼é€’å¢çš„ç­‰å·®æ•°åˆ—
#
# å¯¼å‡ºå†…å®¹ï¼ˆCSVï¼‰ï¼š
#   - å½“å‰æ¯”èµ›åºå·ã€å½“å‰ä¸»é˜Ÿ/å®¢é˜Ÿ
#   - å†å²ä¸»é˜Ÿ/å®¢é˜Ÿ
#   - å†å²æ¯”èµ›åºå·ã€å†å²æ¯”èµ›ç»“æœã€å†å²PRO_æœ€ç»ˆé¢„æµ‹ç»“æœã€å†å²PRO_gapã€å†å²PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœã€å†å²PROèåˆæ¨¡å‹_gapï¼ˆ4 ä½å°æ•°ï¼‰
#   - equal_pro / diff1_pro / equal_ens / diff1_ens / equal_cross / diff1_cross / total_count / parity
#   - PRO_gap_top5_trunc / PRO_gap_has_ap / PRO_gap_ap_triplet
#   - ENS_gap_top5_trunc / ENS_gap_has_ap / ENS_gap_ap_triplet
#   - åœ¨ä¸åŒâ€œå½“å‰æ¯”èµ›åºå·â€çš„ Top5 ä¹‹é—´æ’å…¥ä¸€è¡Œç©ºç™½è¡Œ

import math
import re
from pathlib import Path
from typing import Optional, Tuple, List

import numpy as np
import pandas as pd
import streamlit as st

from models.pro_model import predict_model_pro
from models.model_pro_ensemble import predict_model_pro_ensemble
from models.predict_model_meta import predict_model_meta
from similarity_matcher import SimilarityMatcher

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ UI è®¾ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="å†å²ç›¸ä¼¼æ¯”èµ› Top5 å¯¼å‡º", layout="wide")

st.markdown("""
<style>
.stApp { background:linear-gradient(135deg,#f0f8ff,#e6e6fa); }
.company-name{font-size:1.05em;font-weight:600;text-shadow:1px 1px 2px rgba(0,0,0,0.2);}
.stTextInput>div>div>input{max-width:260px;}
.stButton>button{margin-top:4px;margin-bottom:8px;}

/* ç´§å‡‘å†å²è¡¨æ ¼æ ·å¼ */
.hist-table{
  table-layout: fixed;
  width: 100%;
  border-collapse: collapse;
}
.hist-table th, .hist-table td{
  max-width: 80px;
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
  padding: 3px 4px;
  border-bottom: 1px solid #ddd;
  font-size: 0.85rem;
}
.hist-table th{
  font-weight: 600;
  background-color:#f5f5ff;
}

/* å·®å€¼æ¨¡å¼çš„å°è¡¨æ ¼ */
.pattern-table{
  border-collapse: collapse;
  margin-top: 4px;
}
.pattern-table th, .pattern-table td{
  border: 1px solid #ddd;
  padding: 3px 6px;
  font-size: 0.85rem;
}
.pattern-table th{
  background-color:#eef2ff;
  font-weight: 600;
}
</style>
""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ åŸºæœ¬å¸¸é‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR  = Path(__file__).parent
DATA_FILE = BASE_DIR / "data" / "new_matches.xlsx"
HIST_PATH = BASE_DIR / "data" / "prediction_results (43).xlsx"

companies = ["Bet365","ç«‹åš","Interwetten","Pinnacle","William Hill"]
TEAM_COLS = ["ä¸»é˜Ÿ", "å®¢é˜Ÿ"]
outcomes  = ["ä¸»èƒœ","å¹³å±€","å®¢èƒœ"]
ODDS_COLS = [f"{c}_{o}" for c in companies for o in outcomes]
OUTCOME_COL = "æ¯”èµ›ç»“æœ"

# ---------- æ¸²æŸ“ç´§å‡‘è¡¨æ ¼ ----------
def render_compact_table(df: pd.DataFrame):
    """ç”¨å›ºå®šåˆ—å®½çš„ HTML è¡¨æ ¼ç´§å‡‘æ˜¾ç¤º DataFrameï¼Œå¹¶ç»Ÿä¸€æ•°å€¼ä¸º 4 ä½å°æ•°ã€‚"""
    if df is None or df.empty:
        st.info("æš‚æ— æ•°æ®ã€‚")
        return
    html = df.to_html(
        index=False,
        classes="hist-table",
        border=0,
        escape=False,
        float_format=lambda x: f"{x:.4f}",
    )
    st.markdown(html, unsafe_allow_html=True)

# ---------- è¯†åˆ«â€œæ¯”èµ›ç»“æœâ€åˆ—å ----------
def get_result_value(row: pd.Series) -> str:
    """ä»ä¸€è¡Œä¸­å–æ¯”èµ›ç»“æœï¼šä¼˜å…ˆæ¯”èµ›ç»“æœï¼Œå…¶æ¬¡æ¯”èµ›ç»“æœ_yï¼Œå†å…¶æ¬¡æ¯”èµ›ç»“æœ_xã€‚"""
    for col in ["æ¯”èµ›ç»“æœ", "æ¯”èµ›ç»“æœ_y", "æ¯”èµ›ç»“æœ_x"]:
        if col in row and pd.notna(row[col]) and str(row[col]) != "":
            return str(row[col])
    return ""

# ---------- å·®å€¼æ¨¡å¼å·¥å…· ----------
def _truncate_two_decimals(x: float) -> float:
    try:
        x = float(x)
    except (TypeError, ValueError):
        return 0.0
    if x >= 0:
        return math.floor(x * 100 + 1e-8) / 100.0
    else:
        return math.ceil(x * 100 - 1e-8) / 100.0


def format_gap_pattern(values) -> str:
    """
    ä¼ å…¥é•¿åº¦ä¸º 3 çš„ gap åˆ—è¡¨ï¼Œè¿”å›å½¢å¦‚ '(outer)d1-d2' çš„å­—ç¬¦ä¸²ã€‚
    """
    if len(values) != 3:
        return ""
    vs = sorted(_truncate_two_decimals(v) for v in values)
    d1 = int(math.floor(abs(vs[1] - vs[0]) * 100 + 1e-8))
    d2 = int(math.floor(abs(vs[2] - vs[1]) * 100 + 1e-8))
    if (d1 == 0 and d2 != 0) or (d2 == 0 and d1 != 0):
        first, second = 0, d2 if d1 == 0 else d1
    else:
        first, second = d1, d2
    outer = abs(first - second)
    return f"({outer}){first}-{second}"


def compute_gap_patterns(sims: pd.DataFrame, col: str) -> dict:
    """
    ä»å†å²ç›¸ä¼¼æ¯”èµ›ç»“æœ sims ä¸­ï¼Œä¸ºæŒ‡å®š gap åˆ—ï¼ˆå¦‚ 'PRO_gap' æˆ– 'PROèåˆæ¨¡å‹_gap'ï¼‰
    è®¡ç®— 0-1-2, 1-2-3, 2-3-4 ä¸‰ä¸ªçª—å£çš„å·®å€¼æ¨¡å¼ã€‚
    """
    if col not in sims.columns:
        return {}
    vals = sims[col].tolist()
    windows = [("0-1-2", 0), ("1-2-3", 1), ("2-3-4", 2)]
    patterns = {}
    for label, start in windows:
        if len(vals) >= start + 3:
            triple = vals[start:start + 3]
            patterns[label] = format_gap_pattern(triple)
    return patterns

# ---------- PRO_gap & ENS_gap ç­‰å·®ä¸‰å…ƒç»„å·¥å…· ----------

def compute_gap_ap(sims: pd.DataFrame, col: str):
    """
    å¯¹å½“å‰æ¯”èµ›çš„ Top5æŸåˆ— gapï¼ˆå¦‚ PRO_gap æˆ– PROèåˆæ¨¡å‹_gapï¼‰ï¼š
      - å…ˆæˆªæ–­åˆ°ä¸¤ä½å°æ•°ï¼ˆä¸å››èˆäº”å…¥ï¼‰ï¼›
      - å†æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä»»æ„ä¸‰ä¸ªå€¼æ„æˆä¸¥æ ¼é€’å¢çš„ç­‰å·®æ•°åˆ—ï¼›
    è¿”å›ï¼š
      - trunc_list: æˆªæ–­åçš„å‰ 5 ä¸ª gap åˆ—è¡¨ï¼ˆæŒ‰ Top5 é¡ºåºï¼‰
      - has_ap: 1 / 0
      - ap_triplet: è‹¥å­˜åœ¨ï¼Œè¿”å› (a,b,c) ä¸‰ä¸ª floatï¼›å¦åˆ™ None
    """
    if col not in sims.columns or sims.empty:
        return [], 0, None
    gaps = sims[col].tolist()
    trunc = [_truncate_two_decimals(x) for x in gaps]
    ints = [int(round(v * 100)) for v in trunc]
    uniq = sorted(set(ints))

    has_ap = 0
    ap_triplet = None
    n = len(uniq)
    for i in range(n):
        for j in range(i+1, n):
            for k in range(j+1, n):
                a, b, c = uniq[i], uniq[j], uniq[k]
                if b > a and c > b and (b - a) == (c - b):
                    has_ap = 1
                    ap_triplet = (a / 100.0, b / 100.0, c / 100.0)
                    break
            if has_ap:
                break
        if has_ap:
            break

    return trunc, has_ap, ap_triplet

# ---------- æ¨¡å¼è§£æ & è®¡æ•°ä½“ç³» ----------

def parse_pair_from_pattern(pat: str) -> Optional[Tuple[int,int]]:
    """
    ä»æ¨¡å¼å­—ç¬¦ä¸²ä¸­è§£ææœ€åä¸¤ä¸ªæ­£æ•´æ•° (a,b)ï¼š
      "(5)8-3" -> (8,3)
      "2-7"    -> (2,7)
    æ³¨æ„ï¼šå¿½ç•¥ '-' ç¬¦å·ï¼ŒæŠŠå®ƒå½“åˆ†éš”ç¬¦ï¼Œè€Œä¸æ˜¯è´Ÿå·ã€‚
    """
    if not isinstance(pat, str) or not pat.strip():
        return None
    nums = re.findall(r"\d+", pat)
    if len(nums) < 2:
        return None
    a, b = int(nums[-2]), int(nums[-1])
    return a, b

def delta_from_pattern(pat: str) -> Optional[int]:
    """Î” = |b - a|"""
    pair = parse_pair_from_pattern(pat)
    if pair is None:
        return None
    a, b = pair
    return abs(b - a)

def compute_pattern_counts_for_match(
    pro0: str, pro1: str, pro2: str,
    ens0: str, ens1: str, ens2: str,
):
    """
    åŸºäº 6 ä¸ªæ¨¡å¼è®¡ç®—ï¼š
      - PRO å†…éƒ¨ï¼šequal_proï¼ˆÎ” ç›¸ç­‰ï¼‰ã€diff1_proï¼ˆÎ” å·®1ä¸”ä¸¤æ¨¡å¼ä¸­è‡³å°‘æœ‰ä¸€ä¸ªæ•°å­—ç›¸åŒï¼‰
      - ENS å†…éƒ¨ï¼šequal_ensã€diff1_ens
      - PRO vs ENS äº¤å‰ï¼šequal_crossï¼ˆÎ” ç›¸ç­‰ï¼‰ã€diff1_crossï¼ˆÎ” å·®1ä¸”ä¸¤ä¸ªæ¨¡å¼ä¹‹é—´æ— å…±åŒæ•°å­—ï¼‰
      - total_count / parity
    """

    pro_pats = [pro0, pro1, pro2]
    ens_pats = [ens0, ens1, ens2]

    pro_pairs = [parse_pair_from_pattern(p) for p in pro_pats]
    pro_deltas = [delta_from_pattern(p) for p in pro_pats]

    ens_pairs = [parse_pair_from_pattern(p) for p in ens_pats]
    ens_deltas = [delta_from_pattern(p) for p in ens_pats]

    # 1) PRO å†…éƒ¨
    equal_pro = 0
    diff1_pro = 0
    for i in range(3):
        for j in range(i+1, 3):
            di, dj = pro_deltas[i], pro_deltas[j]
            pi, pj = pro_pairs[i], pro_pairs[j]
            if di is None or dj is None or pi is None or pj is None:
                continue
            if di == dj:
                equal_pro += 1
            if abs(di - dj) == 1:
                if set(pi) & set(pj):
                    diff1_pro += 1

    # 2) ENS å†…éƒ¨
    equal_ens = 0
    diff1_ens = 0
    for i in range(3):
        for j in range(i+1, 3):
            di, dj = ens_deltas[i], ens_deltas[j]
            pi, pj = ens_pairs[i], ens_pairs[j]
            if di is None or dj is None or pi is None or pj is None:
                continue
            if di == dj:
                equal_ens += 1
            if abs(di - dj) == 1:
                if set(pi) & set(pj):
                    diff1_ens += 1

    # 3) PRO vs ENS äº¤å‰ï¼š3Ã—3 = 9 å¯¹
    equal_cross = 0
    diff1_cross = 0
    for i in range(3):
        for j in range(3):
            di, dj = pro_deltas[i], ens_deltas[j]
            pi, pj = pro_pairs[i], ens_pairs[j]
            if di is None or dj is None or pi is None or pj is None:
                continue
            if di == dj:
                equal_cross += 1
            if abs(di - dj) == 1:
                # ä¸¤ä¸ªæ¨¡å¼ä¹‹é—´ä¸èƒ½æœ‰å…±åŒæ•°å­—
                if not (set(pi) & set(pj)):
                    diff1_cross += 1

    total = equal_pro + diff1_pro + equal_ens + diff1_ens + equal_cross + diff1_cross
    parity = 1 if total % 2 == 1 else 0

    return {
        "equal_pro": equal_pro,
        "diff1_pro": diff1_pro,
        "equal_ens": equal_ens,
        "diff1_ens": diff1_ens,
        "equal_cross": equal_cross,
        "diff1_cross": diff1_cross,
        "total_count": total,
        "parity": parity,
    }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. Session åˆå§‹åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("âš½ å†å²ç›¸ä¼¼æ¯”èµ› Top5 æŸ¥çœ‹ä¸å¯¼å‡º")

if "input_df" not in st.session_state:
    st.session_state.input_df = pd.DataFrame(columns=TEAM_COLS + ODDS_COLS)
if "matcher" not in st.session_state:
    if not HIST_PATH.exists():
        st.error(f"æ‰¾ä¸åˆ°å†å²åº“æ–‡ä»¶ï¼š{HIST_PATH}")
    else:
        st.session_state.matcher = SimilarityMatcher(str(HIST_PATH))

# ---------- æ•°æ®è¾“å…¥ ----------
mode = st.radio("ğŸ“¥ æ•°æ®è¾“å…¥æ–¹å¼", ["ä¸Šä¼ æ–‡ä»¶", "æ‰‹åŠ¨å½•å…¥"], horizontal=True)

if mode == "ä¸Šä¼ æ–‡ä»¶":
    up = st.file_uploader("ä¸Šä¼ èµ”ç‡æ–‡ä»¶ (å»ºè®®åŒ…å«ä¸»é˜Ÿ/å®¢é˜Ÿ + 15åˆ—èµ”ç‡)", type=["xlsx", "csv"])
    if up is not None:
        df_up = pd.read_csv(up) if up.name.endswith(".csv") else pd.read_excel(up)
        for col in TEAM_COLS:
            if col not in df_up.columns:
                df_up[col] = ""
        missing_odds = [c for c in ODDS_COLS if c not in df_up.columns]
        if missing_odds:
            st.error(f"ä¸Šä¼ æ–‡ä»¶ç¼ºå°‘ä»¥ä¸‹èµ”ç‡åˆ—ï¼š{missing_odds}")
        else:
            st.session_state.input_df = df_up[TEAM_COLS + ODDS_COLS].copy()
            st.success(f"âœ… å·²è¯»å– {len(df_up)} åœºæ¯”èµ›")
            st.dataframe(st.session_state.input_df)
else:
    st.subheader("ğŸ–Š æ‰‹åŠ¨å½•å…¥ (é€å…¬å¸ä¸€è¡Œ)")
    with st.form("manual", clear_on_submit=True):
        c1, c2 = st.columns(2)
        home_team = c1.text_input("ä¸»é˜Ÿåç§°", key="home_team")
        away_team = c2.text_input("å®¢é˜Ÿåç§°", key="away_team")

        inps = {}
        st.markdown("è¯·è¾“å…¥å„åšå½©å…¬å¸èµ”ç‡ï¼ˆæ ¼å¼ï¼šä¸»èƒœ å¹³å±€ å®¢èƒœï¼Œä¾‹å¦‚ï¼š2.05 3.60 3.50ï¼‰")
        for comp in companies:
            r1, r2 = st.columns([1, 2])
            r1.markdown(f"<div class='company-name'>{comp}</div>", unsafe_allow_html=True)
            inps[comp] = r2.text_input("", placeholder="2.05 3.60 3.50", key=f"man_{comp}")
        if st.form_submit_button("æ·»åŠ æ¯”èµ›"):
            row_odds = []
            ok = True
            for comp in companies:
                parts = inps[comp].split()
                if len(parts) != 3:
                    st.error(f"{comp} éœ€è¾“å…¥ 3 ä¸ªèµ”ç‡"); ok = False; break
                try:
                    row_odds += [float(x) for x in parts]
                except ValueError:
                    st.error(f"{comp} çš„èµ”ç‡å¿…é¡»æ˜¯æ•°å­—"); ok = False; break
            if ok:
                new_row = pd.DataFrame([[home_team, away_team] + row_odds],
                                       columns=TEAM_COLS + ODDS_COLS)
                st.session_state.input_df = pd.concat(
                    [st.session_state.input_df, new_row],
                    ignore_index=True
                )
                st.success("âœ… å·²æ·»åŠ 1åœºæ¯”èµ›")
                st.dataframe(st.session_state.input_df)

# ---------- å†å²ç›¸ä¼¼ Top5 æ˜¾ç¤º + å·®å€¼æ¨¡å¼ + è®¡æ•° + ç­‰å·®ä¸‰å…ƒç»„ + å¯¼å‡º ----------
if not st.session_state.input_df.empty and "matcher" in st.session_state:
    st.subheader("ğŸ” å†å²ç›¸ä¼¼æ¯”èµ› Top5ï¼ˆæŒ‰ SimilarityMatcher åŸå§‹é¡ºåºï¼‰")

    df_odds = st.session_state.input_df[ODDS_COLS].copy()

    # å½“å‰æ¯”èµ› PRO æ¨¡å‹é¢„æµ‹ï¼ˆç”¨äº q_basicï¼‰
    df_pro = predict_model_pro(df_odds)
    prob_cols = [c for c in df_pro.columns if c.startswith("P(")]
    for pc in prob_cols:
        df_pro[pc].fillna(0, inplace=True)

    # PRO èåˆè¾“å‡º
    ens_in = pd.concat([
        df_odds.reset_index(drop=True),
        df_pro[["average_gap"] + prob_cols].reset_index(drop=True)
    ], axis=1)
    try:
        df_ens = predict_model_pro_ensemble(ens_in)
    except Exception:
        df_ens = pd.DataFrame({
            "PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ": ["å¹³å±€"] * len(df_pro),
            "PROèåˆæ¨¡å‹_gap": [0.0] * len(df_pro)
        })

    # METAï¼ˆç”¨äº q_basicï¼‰
    try:
        df_meta = predict_model_meta(df_odds)
    except Exception:
        df_meta = pd.DataFrame()

    matcher: SimilarityMatcher = st.session_state.matcher

    export_rows = []

    for i in range(len(st.session_state.input_df)):
        home = st.session_state.input_df.loc[i, "ä¸»é˜Ÿ"] if "ä¸»é˜Ÿ" in st.session_state.input_df.columns else ""
        away = st.session_state.input_df.loc[i, "å®¢é˜Ÿ"] if "å®¢é˜Ÿ" in st.session_state.input_df.columns else ""

        title_str = f"ç¬¬ {i+1} åœº"
        if home or away:
            title_str += f"ï¼š{home} vs {away}"
        st.markdown(f"### â–¶ {title_str}")

        # æ„é€  q_basic
        curr_pro_res = df_pro.loc[i, "æœ€ç»ˆé¢„æµ‹ç»“æœ"] if "æœ€ç»ˆé¢„æµ‹ç»“æœ" in df_pro.columns else ""
        curr_ens_res = df_ens.loc[i, "PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ"] if "PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ" in df_ens.columns else ""
        curr_pair = f"{curr_pro_res}-{curr_ens_res}" if curr_pro_res and curr_ens_res else ""

        q_basic = {
            "PRO_gap": df_pro.loc[i, "average_gap"],
            "PROèåˆæ¨¡å‹_gap": df_ens.loc[i, "PROèåˆæ¨¡å‹_gap"],
            "èåˆä¿¡å¿ƒ": df_meta.loc[i, "èåˆä¿¡å¿ƒ"] if "èåˆä¿¡å¿ƒ" in df_meta.columns else 0,
            "æ¨èæ€»åˆ†": df_meta.loc[i, "æ¨èæ€»åˆ†"] if "æ¨èæ€»åˆ†" in df_meta.columns else 0,
            "pair": curr_pair
        }

        # ä¸¥æ ¼ä½¿ç”¨ SimilarityMatcher è¿”å›é¡ºåºï¼šTop5
        try:
            sims_basic_full = matcher.query(q_basic, k=5)
        except Exception as e:
            st.warning(f"å†å²åŒ¹é…è°ƒç”¨å‡ºé”™ï¼š{e}")
            sims_basic_full = pd.DataFrame()

        sims_basic_full = sims_basic_full.reset_index(drop=True)

        if sims_basic_full.empty:
            st.info("æœªæ‰¾åˆ°å†å²ç›¸ä¼¼æ¯”èµ›ã€‚")
            continue

        # è®¡ç®— Top5 çš„ PRO / PROèåˆ å·®å€¼æ¨¡å¼
        pro_patterns = compute_gap_patterns(sims_basic_full, "PRO_gap")
        ens_patterns = compute_gap_patterns(sims_basic_full, "PROèåˆæ¨¡å‹_gap")

        pro0 = pro_patterns.get("0-1-2", "")
        pro1 = pro_patterns.get("1-2-3", "")
        pro2 = pro_patterns.get("2-3-4", "")

        ens0 = ens_patterns.get("0-1-2", "")
        ens1 = ens_patterns.get("1-2-3", "")
        ens2 = ens_patterns.get("2-3-4", "")

        # æ„é€ ç”¨äºæ˜¾ç¤ºçš„ DataFrame
        sims_show = sims_basic_full.copy()

        # æ¯”èµ›åºå·ï¼šå†å²åº“ä¸­é€šå¸¸æ˜¯â€œæ¯”èµ›ç¼–å·â€
        if "æ¯”èµ›åºå·" not in sims_show.columns:
            if "æ¯”èµ›ç¼–å·" in sims_show.columns:
                sims_show["æ¯”èµ›åºå·"] = sims_show["æ¯”èµ›ç¼–å·"]
            else:
                sims_show["æ¯”èµ›åºå·"] = ""

        # æ¯”èµ›ç»“æœï¼šè‡ªåŠ¨ä» æ¯”èµ›ç»“æœ / æ¯”èµ›ç»“æœ_y / æ¯”èµ›ç»“æœ_x ä¸­å–
        if "æ¯”èµ›ç»“æœ" not in sims_show.columns:
            if "æ¯”èµ›ç»“æœ_y" in sims_show.columns:
                sims_show["æ¯”èµ›ç»“æœ"] = sims_show["æ¯”èµ›ç»“æœ_y"]
            elif "æ¯”èµ›ç»“æœ_x" in sims_show.columns:
                sims_show["æ¯”èµ›ç»“æœ"] = sims_show["æ¯”èµ›ç»“æœ_x"]
            else:
                sims_show["æ¯”èµ›ç»“æœ"] = ""

        for col in ["PRO_æœ€ç»ˆé¢„æµ‹ç»“æœ", "PRO_gap", "PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ", "PROèåˆæ¨¡å‹_gap"]:
            if col not in sims_show.columns:
                sims_show[col] = ""

        sims_show = sims_show[["æ¯”èµ›åºå·", "æ¯”èµ›ç»“æœ", "PRO_æœ€ç»ˆé¢„æµ‹ç»“æœ", "PRO_gap",
                               "PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ", "PROèåˆæ¨¡å‹_gap"]]

        # æ•°å€¼åˆ—ä¿ç•™ 4 ä½å°æ•°ï¼ˆæ˜¾ç¤ºï¼‰
        for col in ["PRO_gap", "PROèåˆæ¨¡å‹_gap"]:
            if col in sims_show.columns:
                sims_show[col] = pd.to_numeric(sims_show[col], errors="coerce").round(4)

        # æ˜¾ç¤º Top5 å†å²ç›¸ä¼¼æ¯”èµ›
        render_compact_table(sims_show)

        # æ˜¾ç¤ºå†å² Top5 çš„ 6 ä¸ªå·®å€¼æ¨¡å¼
        if pro0 or pro1 or pro2 or ens0 or ens1 or ens2:
            st.markdown("**å·®å€¼æ¨¡å¼ï¼ˆåŸºäºå†å² Top5ï¼‰**")
            pattern_html = f"""
<table class="pattern-table">
  <tr>
    <th></th>
    <th>0-1-2</th>
    <th>1-2-3</th>
    <th>2-3-4</th>
  </tr>
  <tr>
    <th>PRO_gap</th>
    <td>{pro0}</td>
    <td>{pro1}</td>
    <td>{pro2}</td>
  </tr>
  <tr>
    <th>PROèåˆæ¨¡å‹_gap</th>
    <td>{ens0}</td>
    <td>{ens1}</td>
    <td>{ens2}</td>
  </tr>
</table>
"""
            st.markdown(pattern_html, unsafe_allow_html=True)

        # è®¡ç®—å½“å‰æ¯”èµ›çš„æ¨¡å¼è®¡æ•°
        counts = compute_pattern_counts_for_match(pro0, pro1, pro2, ens0, ens1, ens2)
        st.caption(
            f"è®¡æ•°ç»“æœï¼š"
            f"PRO å†… equal={counts['equal_pro']}, diffÂ±1={counts['diff1_pro']}ï¼›"
            f"ENS å†… equal={counts['equal_ens']}, diffÂ±1={counts['diff1_ens']}ï¼›"
            f"äº¤å‰ equal={counts['equal_cross']}, diffÂ±1={counts['diff1_cross']}ï¼›"
            f"æ€»æ¬¡æ•°={counts['total_count']}, parity={counts['parity']}ï¼ˆ0=å¶æ•°,1=å¥‡æ•°ï¼‰"
        )

        # è®¡ç®— PRO_gap Top5 æˆªæ–­å€¼ + ç­‰å·®ä¸‰å…ƒç»„
        pro_trunc_list, pro_has_ap, pro_ap_triplet = compute_gap_ap(sims_basic_full, "PRO_gap")
        pro_trunc_str = ", ".join(f"{v:.2f}" for v in pro_trunc_list) if pro_trunc_list else "æ— "
        if pro_has_ap and pro_ap_triplet:
            pro_triplet_str = "ã€".join(f"{v:.2f}" for v in pro_ap_triplet)
            st.caption(
                f"PRO_gap Top5 æˆªæ–­ä¸¤ä½å°æ•°å: {pro_trunc_str}ï¼›å­˜åœ¨ç­‰å·®é€’å¢ä¸‰å…ƒç»„: æ˜¯ï¼ˆ{pro_triplet_str}ï¼‰"
            )
        else:
            st.caption(
                f"PRO_gap Top5 æˆªæ–­ä¸¤ä½å°æ•°å: {pro_trunc_str}ï¼›å­˜åœ¨ç­‰å·®é€’å¢ä¸‰å…ƒç»„: å¦"
            )

        pro_trunc_str_for_export = ",".join(f"{v:.2f}" for v in pro_trunc_list)
        pro_ap_triplet_str = ""
        if pro_has_ap and pro_ap_triplet:
            pro_ap_triplet_str = "|".join(f"{v:.2f}" for v in pro_ap_triplet)

        # è®¡ç®— PROèåˆæ¨¡å‹_gap Top5 æˆªæ–­å€¼ + ç­‰å·®ä¸‰å…ƒç»„
        ens_trunc_list, ens_has_ap, ens_ap_triplet = compute_gap_ap(sims_basic_full, "PROèåˆæ¨¡å‹_gap")
        ens_trunc_str = ", ".join(f"{v:.2f}" for v in ens_trunc_list) if ens_trunc_list else "æ— "
        if ens_has_ap and ens_ap_triplet:
            ens_triplet_str = "ã€".join(f"{v:.2f}" for v in ens_ap_triplet)
            st.caption(
                f"PROèåˆæ¨¡å‹_gap Top5 æˆªæ–­ä¸¤ä½å°æ•°å: {ens_trunc_str}ï¼›å­˜åœ¨ç­‰å·®é€’å¢ä¸‰å…ƒç»„: æ˜¯ï¼ˆ{ens_triplet_str}ï¼‰"
            )
        else:
            st.caption(
                f"PROèåˆæ¨¡å‹_gap Top5 æˆªæ–­ä¸¤ä½å°æ•°å: {ens_trunc_str}ï¼›å­˜åœ¨ç­‰å·®é€’å¢ä¸‰å…ƒç»„: å¦"
            )

        ens_trunc_str_for_export = ",".join(f"{v:.2f}" for v in ens_trunc_list)
        ens_ap_triplet_str = ""
        if ens_has_ap and ens_ap_triplet:
            ens_ap_triplet_str = "|".join(f"{v:.2f}" for v in ens_ap_triplet)

        # ===== å‡†å¤‡å¯¼å‡ºè¡Œï¼ˆä¿æŒå½“å‰å¾ªç¯çš„ Top5 é¡ºåºï¼‰ =====
        hist_home_col = "ä¸»é˜Ÿ" if "ä¸»é˜Ÿ" in sims_basic_full.columns else None
        hist_away_col = "å®¢é˜Ÿ" if "å®¢é˜Ÿ" in sims_basic_full.columns else None

        for _, row in sims_basic_full.iterrows():
            export_rows.append({
                "å½“å‰æ¯”èµ›åºå·": i + 1,
                "å½“å‰ä¸»é˜Ÿ": home,
                "å½“å‰å®¢é˜Ÿ": away,
                "å†å²æ¯”èµ›åºå·": row["æ¯”èµ›åºå·"] if "æ¯”èµ›åºå·" in row else row.get("æ¯”èµ›ç¼–å·", ""),
                "å†å²æ¯”èµ›ç»“æœ": get_result_value(row),
                "å†å²PRO_æœ€ç»ˆé¢„æµ‹ç»“æœ": row.get("PRO_æœ€ç»ˆé¢„æµ‹ç»“æœ", ""),
                "å†å²PRO_gap": row.get("PRO_gap", ""),
                "å†å²PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ": row.get("PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ", ""),
                "å†å²PROèåˆæ¨¡å‹_gap": row.get("PROèåˆæ¨¡å‹_gap", ""),
                "å†å²ä¸»é˜Ÿ": row.get(hist_home_col, "") if hist_home_col else "",
                "å†å²å®¢é˜Ÿ": row.get(hist_away_col, "") if hist_away_col else "",
                "equal_pro": counts["equal_pro"],
                "diff1_pro": counts["diff1_pro"],
                "equal_ens": counts["equal_ens"],
                "diff1_ens": counts["diff1_ens"],
                "equal_cross": counts["equal_cross"],
                "diff1_cross": counts["diff1_cross"],
                "total_count": counts["total_count"],
                "parity": counts["parity"],
                "PRO_gap_top5_trunc": pro_trunc_str_for_export,
                "PRO_gap_has_ap": pro_has_ap,
                "PRO_gap_ap_triplet": pro_ap_triplet_str,
                "ENS_gap_top5_trunc": ens_trunc_str_for_export,
                "ENS_gap_has_ap": ens_has_ap,
                "ENS_gap_ap_triplet": ens_ap_triplet_str,
            })

    # å¯¼å‡ºå…¨éƒ¨æ¯”èµ›çš„ Top5 å†å²ç›¸ä¼¼åˆ—è¡¨
    if export_rows:
        df_export = pd.DataFrame(export_rows)

        # æ•°å€¼åˆ—ç»Ÿä¸€ä¿ç•™ 4 ä½å°æ•°
        for col in ["å†å²PRO_gap", "å†å²PROèåˆæ¨¡å‹_gap"]:
            if col in df_export.columns:
                df_export[col] = pd.to_numeric(df_export[col], errors="coerce").round(4)

        # ä¸æ’åºï¼Œä¿æŒ append çš„ Top5 é¡ºåºï¼›ä»…åœ¨æ¯”èµ›ä¹‹é—´æ’å…¥ç©ºè¡Œ
        rows_with_blank = []
        last_match = None
        for _, row in df_export.iterrows():
            match_no = row["å½“å‰æ¯”èµ›åºå·"]
            if last_match is not None and match_no != last_match:
                rows_with_blank.append({col: "" for col in df_export.columns})
            rows_with_blank.append(row.to_dict())
            last_match = match_no

        df_export_with_blank = pd.DataFrame(rows_with_blank, columns=df_export.columns)

        st.subheader("ğŸ“¤ å¯¼å‡ºæ‰€æœ‰æ¯”èµ›çš„å†å²ç›¸ä¼¼ Top5ï¼ˆå«çƒé˜Ÿåç§°ã€æ¨¡å¼è®¡æ•°ä¸ç­‰å·®ä¸‰å…ƒç»„ï¼‰")
        render_compact_table(df_export_with_blank.head(30))  # é¢„è§ˆå‰ 30 è¡Œ

        st.download_button(
            "â¬‡ï¸ å¯¼å‡ºå†å²ç›¸ä¼¼ Top5ï¼ˆCSVï¼Œ4ä½å°æ•°+åˆ†ç»„ç©ºè¡Œï¼‰",
            df_export_with_blank.to_csv(index=False).encode("utf-8-sig"),
            "all_matches_top5_history_with_counts_and_ap.csv",
            "text/csv",
        )
