import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier

# å¯¼å…¥ PRO å’Œ META æ¨¡å‹æ¥å£
from models.pro_model import predict_model_pro
from models.model_pro_ensemble import predict_model_pro_ensemble
from models.predict_model_meta import predict_model_meta
from similarity_matcher import SimilarityMatcher

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ CSS Styling â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<style>
.stApp { background: linear-gradient(135deg, #f0f8ff, #e6e6fa); }
.company-name { font-size:1.1em; font-weight:600; text-shadow:1px 1px 2px rgba(0,0,0,0.2); }
.stTextInput>div>div>input { max-width:200px; }
.stButton>button { margin-top:4px; margin-bottom:8px; }
</style>
""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ åŠ è½½å¤šæ¨¡å‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_models():
    data_file = Path(__file__).parent / 'data' / 'new_matches.xlsx'
    df = pd.read_excel(data_file)
    feat_cols = [c for c in df.columns if c not in ['æ¯”èµ›','æ¯”èµ›ç»“æœ']]
    X = df[feat_cols].values
    # éšå«æ¦‚ç‡è½¬æ¢
    X_imp = X.copy()
    for j in range(0, X_imp.shape[1], 3):
        inv = 1 / X_imp[:, j:j+3]
        X_imp[:, j:j+3] = inv / inv.sum(axis=1, keepdims=True)
    # åŸå§‹æ ‡ç­¾
    y = df['æ¯”èµ›ç»“æœ'].map({'ä¸»èƒœ':0,'å¹³å±€':1,'å®¢èƒœ':2}).values
    # æ ·æœ¬æƒé‡ï¼ˆå¹³å±€å¢å¼ºï¼‰
    w = np.array([1.0 if yi==0 else 0.6 if yi==1 else 1.0 for yi in y])

    # ä¸€é˜¶æ®µï¼šå¹³å±€ vs éå¹³å±€
    y_draw = (y == 1).astype(int)
    draw_clf = HistGradientBoostingClassifier(
        learning_rate=0.01, max_depth=5, loss='log_loss', random_state=42
    )
    draw_clf.fit(X_imp, y_draw)
    tree_clf = DecisionTreeClassifier(max_depth=3, random_state=42)
    tree_clf.fit(X_imp, y_draw)

    # äºŒé˜¶æ®µï¼šèƒœè´Ÿæ¨¡å‹ï¼ˆéå¹³å±€å­é›†ï¼‰
    mask = (y != 1)
    X_wl, y_wl = X_imp[mask], (y[mask] == 0).astype(int)
    winlose_clf = HistGradientBoostingClassifier(
        learning_rate=0.01, max_depth=5, loss='log_loss', random_state=42
    )
    winlose_clf.fit(X_wl, y_wl)

    # å¤‡ç”¨ä¸‰åˆ†ç±»æ¨¡å‹
    multi_clf = HistGradientBoostingClassifier(
        learning_rate=0.01, max_depth=5, loss='log_loss', random_state=42
    )
    multi_clf.fit(X_imp, y, sample_weight=w)

    return feat_cols, draw_clf, tree_clf, winlose_clf, multi_clf

soccer_feats, draw_clf, tree_clf, winlose_clf, multi_clf = load_models()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ é¡µé¢è®¾ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title='äºŒé˜¶æ®µ+æ ‘å¹³å±€ ç»¼åˆé¢„æµ‹', layout='wide')
st.title('âš½ äºŒé˜¶æ®µ + æ ‘ å¹³å±€èåˆ é¢„æµ‹å™¨')

company_order = ['Bet365','ç«‹åš','Interwetten','Pinnacle','William Hill']
outcomes      = ['ä¸»èƒœ','å¹³å±€','å®¢èƒœ']
feature_cols  = [f"{c}_{o}" for c in company_order for o in outcomes]

# SessionState åˆå§‹åŒ–
if 'input_df' not in st.session_state:
    st.session_state.input_df = pd.DataFrame(columns=feature_cols)
if 'matcher' not in st.session_state:
    st.session_state.matcher = SimilarityMatcher(
        str(Path(__file__).parent / 'data' / 'prediction_results (43).xlsx')
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ•°æ®è¾“å…¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€
mode = st.radio('ğŸ“¥ æ•°æ®è¾“å…¥æ–¹å¼', ['ä¸Šä¼ æ–‡ä»¶','æ‰‹åŠ¨å½•å…¥'], horizontal=True)
if mode=='ä¸Šä¼ æ–‡ä»¶':
    up = st.file_uploader('ä¸Šä¼ èµ”ç‡ (Excel/CSVï¼Œæ¯è¡Œ15åˆ—)', type=['xlsx','csv'])
    if up:
        df_up = pd.read_csv(up) if up.name.endswith('.csv') else pd.read_excel(up)
        st.session_state.input_df = df_up[feature_cols]
        st.success(f'âœ… å·²è¯»å– {len(df_up)} åœºæ¯”èµ›')
        st.dataframe(st.session_state.input_df)
else:
    st.subheader('ğŸ–Š æ‰‹åŠ¨å½•å…¥ (é€å…¬å¸ä¸€è¡Œ)')
    with st.form('frm_manual', clear_on_submit=True):
        inputs = {}
        for comp in company_order:
            c1,c2 = st.columns([1,2])
            c1.markdown(f"<div class='company-name'>{comp}</div>", unsafe_allow_html=True)
            inputs[comp] = c2.text_input('', placeholder='2.05 3.60 3.50', key=f"man_{comp}")
        if st.form_submit_button('æ·»åŠ æ¯”èµ›'):
            vals=[]
            ok=True
            for comp in company_order:
                pts = inputs[comp].split()
                if len(pts)!=3:
                    st.error(f'âš ï¸ {comp} éœ€è¾“å…¥3ä¸ªèµ”ç‡')
                    ok=False
                    break
                vals.extend([float(x) for x in pts])
            if ok:
                new = pd.DataFrame([vals], columns=feature_cols)
                st.session_state.input_df = pd.concat([
                    st.session_state.input_df, new
                ], ignore_index=True)
                st.success('âœ… æ·»åŠ æˆåŠŸï¼Œè¾“å…¥æ¡†å·²æ¸…ç©º')

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ å†å²åŒ¹é… â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not st.session_state.input_df.empty:
    st.subheader('ğŸ” å†å²ç›¸ä¼¼æ¯”èµ›æ¨è')
    df_pro = predict_model_pro(st.session_state.input_df)
    prob_cols = [c for c in df_pro.columns if c.startswith('P(')]
    for pc in prob_cols:
        df_pro[pc].fillna(0, inplace=True)
    ens_in = pd.concat([
        st.session_state.input_df.reset_index(drop=True),
        df_pro[['average_gap']+prob_cols].reset_index(drop=True)
    ], axis=1)
    try:
        df_ens = predict_model_pro_ensemble(ens_in)
    except:
        df_ens = pd.DataFrame({
            'PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ':['å¹³å±€']*len(df_pro),
            'PROèåˆæ¨¡å‹_gap':[0.0]*len(df_pro)
        })
    try:
        df_meta = predict_model_meta(st.session_state.input_df)
    except:
        df_meta = pd.DataFrame()
    for i in range(len(st.session_state.input_df)):
        q = {
            'PRO_gap':          df_pro.loc[i,'average_gap'],
            'PROèåˆæ¨¡å‹_gap':   df_ens.loc[i,'PROèåˆæ¨¡å‹_gap'],
            'èåˆä¿¡å¿ƒ':         df_meta.loc[i,'èåˆä¿¡å¿ƒ']   if 'èåˆä¿¡å¿ƒ'  in df_meta else 0,
            'æ¨èæ€»åˆ†':         df_meta.loc[i,'æ¨èæ€»åˆ†']   if 'æ¨èæ€»åˆ†'  in df_meta else 0,
            'pair':            f"{df_pro.loc[i,'æœ€ç»ˆé¢„æµ‹ç»“æœ']}-{df_ens.loc[i,'PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ']}"
        }
        sims = pd.DataFrame()
        try:
            sims = st.session_state.matcher.query(q, k=3)
        except:
            pass
        st.markdown(f"**ç¬¬ {i+1} åœº** å†å²ç›¸ä¼¼æ¯”èµ›ï¼š")
        st.dataframe(sims.reset_index(drop=True))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ äºŒé˜¶æ®µ+æ ‘ å¹³å±€èåˆé¢„æµ‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not st.session_state.input_df.empty and st.button('ğŸ¯ è¿è¡Œé¢„æµ‹'):
    df_in = st.session_state.input_df.copy().fillna(method='ffill')
    M = len(df_in)

    # æ„é€ éšå«æ¦‚ç‡ç‰¹å¾
    odds     = df_in[soccer_feats].values.astype(float)
    X_imp_new = odds.copy()
    for j in range(0, X_imp_new.shape[1], 3):
        inv = 1 / X_imp_new[:, j:j+3]
        X_imp_new[:, j:j+3] = inv / inv.sum(axis=1, keepdims=True)

    # 1ï¸âƒ£ å¹³å±€æ¦‚ç‡èåˆ
    p_draw_hgb  = draw_clf.predict_proba(X_imp_new)[:,1]
    p_draw_tree = tree_clf.predict_proba(X_imp_new)[:,1]
    p_base_draw = 0.6 * p_draw_hgb + 0.4 * p_draw_tree
    # éçº¿æ€§ boost (Î±=0.10, Î³=0.50)
    alpha, gamma = 0.10, 0.50
    p_draw = p_base_draw + alpha * np.power(1 - p_base_draw, gamma)
    p_draw = np.clip(p_draw, 0, 1)

    # 2ï¸âƒ£ èƒœè´Ÿæ¦‚ç‡
    p_wl   = winlose_clf.predict_proba(X_imp_new)
    p_base = np.zeros((M,3))
    p_base[:,1] = p_draw
    p_base[:,0] = p_wl[:,1] * (1 - p_draw)
    p_base[:,2] = p_wl[:,0] * (1 - p_draw)

    # 3ï¸âƒ£ PRO+ensemble æ¦‚ç‡
    df_pro2 = predict_model_pro(df_in)
    prob2   = [c for c in df_pro2.columns if c.startswith('P(')]
    for pc in prob2:
        df_pro2[pc].fillna(0, inplace=True)
    ens2_in = pd.concat([
        df_in.reset_index(drop=True),
        df_pro2[['average_gap']+prob2].reset_index(drop=True)
    ], axis=1)
    try:
        df_ens2 = predict_model_pro_ensemble(ens2_in)
        p_ens   = df_ens2[[f'P({o})' for o in outcomes]].values
    except:
        p_ens = np.zeros_like(p_base)

    # 4ï¸âƒ£ META æ¦‚ç‡
    try:
        df_meta2 = predict_model_meta(df_in)
        p_meta   = df_meta2[[f'P({o})' for o in outcomes]].values
    except:
        p_meta = np.zeros_like(p_base)

    # 5ï¸âƒ£ ä¸‰è·¯èåˆ + åˆæ¬¡å½’ä¸€åŒ–
    p_final = (p_base + p_ens + p_meta) / 3
    p_final /= p_final.sum(axis=1, keepdims=True)

    # 6ï¸âƒ£ Upset-boost for ä¸‰ç§ç»“æœ
    odds_mat    = odds.reshape(-1, len(company_order), len(outcomes))  # (M,5,3)
    inv_out     = 1 / odds_mat
    implied_out = inv_out.mean(axis=1)
    implied_out /= implied_out.sum(axis=1, keepdims=True)
    underdog_idx = np.argmin(implied_out, axis=1)

    for i, u in enumerate(underdog_idx):
        p_final[i, u] += alpha * np.power(1 - p_final[i, u], gamma)
    p_final /= p_final.sum(axis=1, keepdims=True)

    # 7ï¸âƒ£ è¾“å‡ºç»“æœ
    preds  = [outcomes[i] for i in np.argmax(p_final, axis=1)]
    df_res = pd.DataFrame(p_final*100,
                          columns=[f'{o}(%)' for o in outcomes])
    df_res.insert(0, 'æœ€ç»ˆé¢„æµ‹', preds)
    df_res.index = np.arange(1, M+1)
    df_res.index.name = 'æ¯”èµ›ç¼–å·'

    st.subheader('ğŸ“Š ç»¼åˆæ¨¡å‹é¢„æµ‹ç»“æœ')
    st.dataframe(df_res, use_container_width=True)
    csv = df_res.to_csv(index=True).encode('utf-8-sig')
    st.download_button('â¬‡ï¸ ä¸‹è½½ç»“æœ', csv, 'predictions.csv', 'text/csv')
