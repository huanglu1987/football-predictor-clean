import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.ensemble import HistGradientBoostingClassifier

# å¯¼å…¥ PRO å’Œ META æ¨¡å‹æ¥å£
from models.pro_model import predict_model_pro
from models.model_pro_ensemble import predict_model_pro_ensemble
from models.predict_model_meta import predict_model_meta
from similarity_matcher import SimilarityMatcher

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ CSS Styling â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<style>
.stApp { background: linear-gradient(135deg, #f0f8ff, #e6e6fa); }
.company-name { font-size:1.1em; font-weight:600; text-shadow:1px 1px 2px rgba(0,0,0,0.2); }
.stTextInput>div>div>input { max-width:200px; }
.stButton>button { margin-top:4px; margin-bottom:8px; }
</style>
""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ åŠ è½½ è¶³çƒ HGB äºŒé˜¶æ®µæ¨¡å‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_soccer_models():
    # è¯»å–å†å²æ•°æ®
    df = pd.read_excel(Path(__file__).parent / 'data' / 'new_matches.xlsx')
    feat_cols = [c for c in df.columns if c not in ['æ¯”èµ›','æ¯”èµ›ç»“æœ']]
    X = df[feat_cols].values
    # éšå«æ¦‚ç‡è½¬æ¢
    X_imp = X.copy()
    for j in range(0, X_imp.shape[1], 3):
        inv = 1 / X_imp[:, j:j+3]
        X_imp[:, j:j+3] = inv / inv.sum(axis=1, keepdims=True)
    # åŸå§‹æ ‡ç­¾
    y = df['æ¯”èµ›ç»“æœ'].map({'ä¸»èƒœ':0,'å¹³å±€':1,'å®¢èƒœ':2}).values
    # 1) å¹³å±€ vs éå¹³å±€ æ¨¡å‹
    y_draw = (y == 1).astype(int)
    draw_clf = HistGradientBoostingClassifier(
        learning_rate=0.01, max_depth=5, loss='log_loss', random_state=42
    )
    draw_clf.fit(X_imp, y_draw)
    # 2) èƒœè´Ÿ æ¨¡å‹ï¼ˆåªç”¨éå¹³å±€æ ·æœ¬ï¼‰
    mask = (y != 1)
    X_winlose = X_imp[mask]
    y_winlose = (y[mask] == 0).astype(int)  # 1=ä¸»èƒœ, 0=å®¢èƒœ
    winlose_clf = HistGradientBoostingClassifier(
        learning_rate=0.01, max_depth=5, loss='log_loss', random_state=42
    )
    winlose_clf.fit(X_winlose, y_winlose)
    # 3) åŸå¤šåˆ†ç±»æ¨¡å‹ï¼Œç”¨äºå¯¹æ¯”æˆ–å¤‡ç”¨
    w = np.array([1.0 if yi==0 else 0.60 if yi==1 else 1.0 for yi in y])
    multi_clf = HistGradientBoostingClassifier(
        learning_rate=0.01, max_depth=5, loss='log_loss', random_state=42
    )
    multi_clf.fit(X_imp, y, sample_weight=w)
    return draw_clf, winlose_clf, multi_clf, feat_cols

# åŠ è½½æ¨¡å‹
draw_clf, winlose_clf, soccer_model, soccer_feats = load_soccer_models()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ é¡µé¢è®¾ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title='ç»¼åˆè¶³çƒé¢„æµ‹å™¨', layout='wide')
st.title('âš½ ç»¼åˆè¶³çƒæ¯”èµ›é¢„æµ‹å™¨ (äºŒé˜¶æ®µå†³ç­–)')

company_order = ['Bet365','ç«‹åš','Interwetten','Pinnacle','William Hill']
outcomes      = ['ä¸»èƒœ','å¹³å±€','å®¢èƒœ']
feature_cols  = [f"{c}_{o}" for c in company_order for o in outcomes]
num_features  = len(feature_cols)

# Session state åˆå§‹åŒ–
if 'input_df' not in st.session_state:
    st.session_state.input_df = pd.DataFrame(columns=feature_cols)
if 'matcher' not in st.session_state:
    st.session_state.matcher = SimilarityMatcher(
        str(Path(__file__).parent / 'data' / 'prediction_results (43).xlsx')
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ•°æ®è¾“å…¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€
mode = st.radio('æ•°æ®è¾“å…¥æ–¹å¼', ['ğŸ“ ä¸Šä¼ æ–‡ä»¶','ğŸ–Š æ‰‹åŠ¨å½•å…¥'], horizontal=True)
if mode=='ğŸ“ ä¸Šä¼ æ–‡ä»¶':
    up = st.file_uploader('ä¸Šä¼ èµ”ç‡æ–‡ä»¶ (Excel/CSVï¼Œæ¯è¡Œ15åˆ—)', type=['xlsx','csv'])
    if up:
        df_up = pd.read_csv(up) if up.name.endswith('.csv') else pd.read_excel(up)
        st.session_state.input_df = df_up[feature_cols]
        st.success(f'âœ… å·²è¯»å– {len(df_up)} åœºæ¯”èµ›')
        st.dataframe(st.session_state.input_df)
else:
    st.subheader('ğŸ–Š æ‰‹åŠ¨å½•å…¥ (é€å…¬å¸ä¸€è¡Œ)')
    with st.form('manual_form', clear_on_submit=True):
        inputs = {}
        for comp in company_order:
            c1,c2 = st.columns([1,2])
            c1.markdown(f"<div class='company-name'>{comp}</div>", unsafe_allow_html=True)
            inputs[comp] = c2.text_input('', placeholder='2.05 3.60 3.50', key=f'man_{comp}')
        if st.form_submit_button('æäº¤å½•å…¥'):
            vals = []
            for comp in company_order:
                parts = inputs[comp].split()
                if len(parts) != 3:
                    st.error(f'âš ï¸ {comp} éœ€3ä¸ªèµ”ç‡ï¼Œå½“å‰{len(parts)}')
                    vals = None
                    break
                vals.extend([float(x) for x in parts])
            if vals and len(vals)==num_features:
                new_row = pd.DataFrame([vals], columns=feature_cols)
                st.session_state.input_df = pd.concat(
                    [st.session_state.input_df, new_row], ignore_index=True
                )
                st.success('âœ… å·²æ·»åŠ 1åœºæ¯”èµ›ï¼Œè¾“å…¥æ¡†å·²æ¸…ç©º')

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ å†å²åŒ¹é… â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not st.session_state.input_df.empty:
    st.subheader('ğŸ” å†å²ç›¸ä¼¼æ¯”èµ›æ¨è')
    df_pro = predict_model_pro(st.session_state.input_df)
    # ...ï¼ˆä¿æŒç°æœ‰åŒ¹é…é€»è¾‘ï¼‰
    # çœç•¥ï¼Œä¸º brevity
    pass

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ é¢„æµ‹ä¸èåˆï¼ˆäºŒé˜¶æ®µå†³ç­–ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not st.session_state.input_df.empty and st.button('ğŸ”„ è¿è¡Œç»¼åˆé¢„æµ‹'):
    df_in = st.session_state.input_df.copy().fillna(method='ffill')
    n = len(df_in)
    # æ„é€ éšå«æ¦‚ç‡ç‰¹å¾
    odds = df_in[soccer_feats].values.astype(float)
    X_imp_new = odds.copy()
    for j in range(0, X_imp_new.shape[1], 3):
        inv = 1 / X_imp_new[:, j:j+3]
        X_imp_new[:, j:j+3] = inv / inv.sum(axis=1, keepdims=True)
    # 1ï¸âƒ£ å¹³å±€é¢„æµ‹
    p_draw = draw_clf.predict_proba(X_imp_new)[:,1]
    # 2ï¸âƒ£ èƒœè´Ÿé¢„æµ‹
    p_winlose = winlose_clf.predict_proba(X_imp_new)  # [:,1]=ä¸»èƒœ
    # åˆæˆ p_soc ä¸¤é˜¶æ®µæ¦‚ç‡åˆ†å¸ƒ
    p_soc_two = np.zeros_like(p_winlose.repeat(3, axis=1)).reshape(n,3)
    p_soc_two[:,1] = p_draw
    p_soc_two[:,0] = p_winlose[:,1] * (1 - p_draw)
    p_soc_two[:,2] = p_winlose[:,0] * (1 - p_draw)
    # PRO èåˆæ¨¡å‹æ¦‚ç‡
    df_pro2 = predict_model_pro(df_in)
    prob_cols2 = [c for c in df_pro2.columns if c.startswith('P(')]
    for pc in prob_cols2:
        df_pro2[pc] = df_pro2[pc].fillna(0)
    ens2_input = pd.concat([
        df_in.reset_index(drop=True),
        df_pro2[['average_gap']+prob_cols2].reset_index(drop=True)
    ], axis=1)
    try:
        df_ens2 = predict_model_pro_ensemble(ens2_input)
        p_ens = df_ens2[[f'P({o})' for o in outcomes]].values
    except:
        p_ens = np.zeros_like(p_soc_two)
    # META æ¨¡å‹æ¦‚ç‡
    try:
        df_meta2 = predict_model_meta(df_in)
        p_meta = df_meta2[[f'P({o})' for o in outcomes]].values
    except:
        p_meta = np.zeros_like(p_soc_two)
    # èåˆæ¦‚ç‡ + å½’ä¸€åŒ–
    p_final = (p_soc_two + p_ens + p_meta) / 3
    p_final /= p_final.sum(axis=1, keepdims=True)
    # ç»“æœå±•ç¤º
    preds = [outcomes[i] for i in np.argmax(p_final, axis=1)]
    res = pd.DataFrame(p_final*100, columns=[f'{o}(%)' for o in outcomes])
    res.insert(0,'æœ€ç»ˆé¢„æµ‹',preds)
    res.index = np.arange(1,n+1)
    res.index.name='æ¯”èµ›ç¼–å·'
    st.subheader('ğŸ“Š ç»¼åˆæ¨¡å‹é¢„æµ‹ç»“æœ (äºŒé˜¶æ®µå†³ç­–)')
    st.dataframe(res, use_container_width=True)
    csv = res.to_csv(index=True).encode('utf-8-sig')
    st.download_button('â¬‡ ä¸‹è½½ç»“æœ', csv, 'predictions.csv', 'text/csv')
