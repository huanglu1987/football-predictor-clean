import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.ensemble import HistGradientBoostingClassifier

# å¯¼å…¥ PRO å’Œ META æ¨¡å‹æ¥å£
from models.pro_model import predict_model_pro
from models.model_pro_ensemble import predict_model_pro_ensemble
from models.predict_model_meta import predict_model_meta
from similarity_matcher import SimilarityMatcher

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CSS Styling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<style>
.stApp { background: linear-gradient(135deg, #f0f8ff, #e6e6fa); }
.company-name { font-size:1.1em; font-weight:600; text-shadow:1px 1px 2px rgba(0,0,0,0.2); }
.stTextInput>div>div>input { max-width:200px; }
.stButton>button { margin-top:4px; margin-bottom:8px; }
</style>
""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åŠ è½½è¶³çƒ HGB æ¨¡å‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_soccer_model():
    data_file = Path(__file__).parent / "data" / "new_matches.xlsx"
    df = pd.read_excel(data_file)
    feat_cols = [c for c in df.columns if c not in ["æ¯”èµ›", "æ¯”èµ›ç»“æœ"]]
    X = df[feat_cols].values
    # éšå«æ¦‚ç‡è½¬æ¢
    X_imp = X.copy()
    for j in range(0, X_imp.shape[1], 3):
        inv = 1 / X_imp[:, j:j+3]
        X_imp[:, j:j+3] = inv / inv.sum(axis=1, keepdims=True)
    # æ ‡ç­¾ç¼–ç 
    y = df["æ¯”èµ›ç»“æœ"].map({"ä¸»èƒœ":0, "å¹³å±€":1, "å®¢èƒœ":2}).values
    # æ‰‹åŠ¨æŒ‡å®šæƒé‡: ä¸»èƒœ=1.0, å¹³å±€=0.8, å®¢èƒœ=1.0
    w = np.array([1.0 if yi==0 else 0.8 if yi==1 else 1.0 for yi in y])
    model = HistGradientBoostingClassifier(
        learning_rate=0.01,
        max_depth=5,
        loss="log_loss",
        random_state=42
    )
    model.fit(X_imp, y, sample_weight=w)
    return model, feat_cols

soccer_model, soccer_feats = load_soccer_model()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Streamlit é¡µé¢è®¾ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ç»¼åˆè¶³çƒé¢„æµ‹å™¨", layout="wide")
st.title("âš½ ç»¼åˆè¶³çƒæ¯”èµ›é¢„æµ‹å™¨")

company_order = ["Bet365", "ç«‹åš", "Interwetten", "Pinnacle", "William Hill"]
outcomes      = ["ä¸»èƒœ", "å¹³å±€", "å®¢èƒœ"]
feature_cols  = [f"{c}_{o}" for c in company_order for o in outcomes]

# Session state åˆå§‹åŒ–
if "input_df" not in st.session_state:
    st.session_state.input_df = pd.DataFrame(columns=feature_cols)
if "matcher" not in st.session_state:
    hist_file = Path(__file__).parent / "data" / "prediction_results (43).xlsx"
    st.session_state.matcher = SimilarityMatcher(str(hist_file))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ•°æ®è¾“å…¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mode = st.radio("æ•°æ®è¾“å…¥æ–¹å¼", ["ğŸ“ ä¸Šä¼ æ–‡ä»¶", "ğŸ–Š æ‰‹åŠ¨å½•å…¥"], horizontal=True)
if mode == "ğŸ“ ä¸Šä¼ æ–‡ä»¶":
    uploaded = st.file_uploader("ä¸Šä¼ èµ”ç‡æ–‡ä»¶ (Excel/CSVï¼Œæ¯è¡Œ15åˆ—)", type=["xlsx","csv"])
    if uploaded:
        df_up = pd.read_csv(uploaded) if uploaded.name.endswith(".csv") else pd.read_excel(uploaded)
        st.session_state.input_df = df_up[feature_cols]
        st.success(f"âœ… å·²è¯»å– {len(df_up)} åœºæ¯”èµ›æ•°æ®")
        st.dataframe(st.session_state.input_df)
else:
    st.subheader("ğŸ–Š æ‰‹åŠ¨å½•å…¥ (é€å…¬å¸ä¸€è¡Œ)")
    with st.form("manual_form", clear_on_submit=True):
        inputs = {}
        for comp in company_order:
            c1, c2 = st.columns([1, 2])
            c1.markdown(f"<div class='company-name'>{comp}</div>", unsafe_allow_html=True)
            inputs[comp] = c2.text_input("", placeholder="2.05 3.60 3.50", key=f"man_{comp}")
        if st.form_submit_button("æäº¤å½•å…¥"):
            vals = []
            for comp in company_order:
                parts = inputs[comp].split()
                vals.extend([float(x) for x in parts])
            st.session_state.input_df.loc[len(st.session_state.input_df)] = vals
            st.success("âœ… å·²æ·»åŠ  1 åœºæ¯”èµ›ï¼Œè¾“å…¥æ¡†å·²æ¸…ç©º")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å†å²ç›¸ä¼¼æ¯”èµ›æ¨è â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not st.session_state.input_df.empty:
    st.subheader("ğŸ” å†å²ç›¸ä¼¼æ¯”èµ›æ¨è")
    # å…ˆè®¡ç®—æ‰€æœ‰è¾…åŠ©ç‰¹å¾
    df_pro  = predict_model_pro(st.session_state.input_df)
    df_ens  = predict_model_pro_ensemble(st.session_state.input_df)
    df_meta = None
    try:
        df_meta = predict_model_meta(st.session_state.input_df)
    except Exception:
        pass

    # è®¡ç®—æ¯åœºæ¯”èµ›çš„åŒ¹é…å‘é‡
    for idx in range(len(st.session_state.input_df)):
        pro_gap      = df_pro.loc[idx, "average_gap"]
        ens_gap      = df_ens.loc[idx, "PROèåˆæ¨¡å‹_gap"]
        fusion_conf  = round(0.6 * ens_gap + 0.4 * pro_gap, 4)  # èåˆä¿¡å¿ƒ
        # å†·é—¨åŸå§‹åˆ†
        row = st.session_state.input_df.loc[idx]
        avg_vals = [np.mean(row[f"{c}_{o}"] for o in outcomes) for c in company_order]
        upset_raw = float(max(avg_vals) - min(avg_vals))
        # å†·é—¨æ ‡å‡†åŒ–åˆ†æ•°éœ€è¦åŸºäºå†å²å‡å€¼/æ ‡å‡†å·®
        # ç®€åŒ–å¤„ç†ï¼šä½¿ç”¨ df_meta ä¸­å·²è®¡ç®—çš„ 'å†·é—¨æ ‡å‡†åŒ–å¾—åˆ†' if exists
        if df_meta is not None and 'å†·é—¨æ ‡å‡†åŒ–å¾—åˆ†' in df_meta.columns:
            upset_norm = df_meta.loc[idx, 'å†·é—¨æ ‡å‡†åŒ–å¾—åˆ†']
        else:
            upset_norm = 0.0
        # æ¨èæ€»åˆ†
        rec_score = round(0.7 * fusion_conf - 0.3 * upset_norm, 4)
        # é…å¯¹æ ‡ç­¾
        pair_tag = f"{df_pro.loc[idx,'æœ€ç»ˆé¢„æµ‹ç»“æœ']}-{df_ens.loc[idx,'PROèåˆæ¨¡å‹é¢„æµ‹ç»“æœ']}"
        # æ„å»ºæŸ¥è¯¢è¡Œ
        query_row = {
            'PRO_gap': pro_gap,
            'PROèåˆæ¨¡å‹_gap': ens_gap,
            'èåˆä¿¡å¿ƒ': fusion_conf,
            'æ¨èæ€»åˆ†': rec_score,
            'pair': pair_tag
        }
        # æ‰§è¡ŒæŸ¥è¯¢
        try:
            sims = st.session_state.matcher.query(query_row, k=3)
        except Exception:
            sims = pd.DataFrame(columns=list(st.session_state.matcher.orig_df.columns) + ['_distance'])
        st.markdown(f"**ç¬¬ {idx+1} åœº** æœ€ç›¸ä¼¼å†å²æ¯”èµ›ï¼š")
        st.dataframe(sims.reset_index(drop=True))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ é¢„æµ‹ä¸èåˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not st.session_state.input_df.empty and st.button("ğŸ”„ è¿è¡Œç»¼åˆé¢„æµ‹"):
    df_in = st.session_state.input_df.copy().fillna(method="ffill")
    n = len(df_in)

    # è¶³çƒ HGB æ¨¡å‹ æ¦‚ç‡
    odds = df_in.values.astype(float)
    Xs   = odds.copy()
    for j in range(0, 15, 3):
        inv = 1 / odds[:, j:j+3]
        Xs[:, j:j+3] = inv / inv.sum(axis=1, keepdims=True)
    p_soc = soccer_model.predict_proba(Xs)

    # META èåˆæ¨¡å‹ æ¦‚ç‡
    try:
        df_meta2 = predict_model_meta(df_in)
        meta_cols2 = [f"P({o})" for o in outcomes]
        p_meta2 = df_meta2[meta_cols2].values if all(c in df_meta2.columns for c in meta_cols2) else np.zeros_like(p_soc)
    except Exception:
        p_meta2 = np.zeros_like(p_soc)

    # æœ€ç»ˆèåˆæ¦‚ç‡ + å½’ä¸€åŒ–
    p_final = (p_soc + p_meta2) / 2.0
    p_final = p_final / p_final.sum(axis=1, keepdims=True)
    preds   = [outcomes[i] for i in np.argmax(p_final, axis=1)]

    # å±•ç¤ºç»“æœ
    res = pd.DataFrame(p_final * 100, columns=[f"{o}(%)" for o in outcomes])
    res.insert(0, "æœ€ç»ˆé¢„æµ‹", preds)
    res.index = np.arange(1, n+1)
    res.index.name = "æ¯”èµ›ç¼–å·"

    st.subheader("ğŸ“Š ç»¼åˆæ¨¡å‹é¢„æµ‹ç»“æœ")
    st.dataframe(res, use_container_width=True)
    csv = res.to_csv(index=True).encode("utf-8-sig")
    st.download_button("â¬‡ ä¸‹è½½ç»“æœ", csv, "predictions.csv", "text/csv")
